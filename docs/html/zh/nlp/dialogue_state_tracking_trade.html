

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>教程 &mdash; nemo 0.10.0b8 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="教程" href="ner.html" />
    <link rel="prev" title="Transformer语言模型" href="transformer_language_model.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> nemo
          

          
          </a>

          
            
            
              <div class="version">
                0.10.0b8
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">简介</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/intro.html">从这里开始</a></li>
<li class="toctree-l1"><a class="reference internal" href="../training.html">快速训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../asr/intro.html">语音识别</a></li>
<li class="toctree-l1"><a class="reference internal" href="../speech_command/intro.html">语音指令</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="intro.html">自然语言处理</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="intro.html#nmt">神经网络机器翻译 (NMT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#bert">BERT</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#transformer">Transformer语言模型</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="intro.html#id2">对话状态跟踪</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">教程</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id2">简介</a></li>
<li class="toctree-l4"><a class="reference internal" href="#multiwoz">MultiWOZ 数据集</a></li>
<li class="toctree-l4"><a class="reference internal" href="#trade">TRADE 模型</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id12">数据预处理</a></li>
<li class="toctree-l4"><a class="reference internal" href="#nemo">构建 NeMo 图</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id13">训练</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id14">指标和结果</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id18">参考</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#ner">命名实体识别 (NER)</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#id3">标点符号和单词首字母大写</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#id4">意图识别和槽填充</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#id5">问答系统</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#bertx2">用 BERTx2 后处理模型来提升语音识别性能</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../tts/intro.html">语音合成</a></li>
<li class="toctree-l1"><a class="reference internal" href="../collections/modules.html">NeMo Collections API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api-docs/modules.html">NeMo API</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">nemo</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="intro.html">自然语言处理</a> &raquo;</li>
        
      <li>教程</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/nlp/dialogue_state_tracking_trade.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="id1">
<h1>教程<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<div class="section" id="id2">
<h2>简介<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p><strong>对话状态追踪 (DST)</strong> <a class="bibtex reference internal" href="#nlp-dst-henderson2015machine" id="id3">[NLP-DST3]</a> 的目标是要为正在进行的对话的状态构建一个表示(representation) 对话是一系列的对话参与者之间的语句。换句话说，DST 系统的目标是能捕捉到用户的目标和意图 然后把它们编码成一系列的**槽(slots)**和槽对应的**值(values)**。</p>
<div class="figure align-default" id="id19">
<img alt="../_images/dst_multiwoz_example.png" src="../_images/dst_multiwoz_example.png" />
<p class="caption"><span class="caption-text">Fig. 1: 一个例子, 多领域对话和相关的状态追踪 (来源: <a class="bibtex reference internal" href="#nlp-dst-wu2019transferable" id="id4">[NLP-DST4]</a>)</span><a class="headerlink" href="#id19" title="Permalink to this image">¶</a></p>
</div>
<p>在这个教程中我们关注多领域对话数据集 MultiWOZ <a class="bibtex reference internal" href="#nlp-dst-budzianowski2018multiwoz" id="id5">[NLP-DST1]</a> 展示如何构建一个 TRADE 模型 <a class="bibtex reference internal" href="#nlp-dst-wu2019transferable" id="id6">[NLP-DST4]</a>, 一个最近发表的领域先进的模型 <strong>多领域(Multi-domain)</strong> 场景会引入一些挑战, 最重要的来自于需要 <strong>多轮映射(multi-turn mapping)</strong>。在一个 <strong>单轮映射(single-turn mapping)</strong> 场景，(<strong>领域(domain)</strong>, <strong>槽(slot)</strong>, <strong>值(value)</strong>) 三元组可以从 单轮中就能推断出。在多轮对话中，这个假设并不存在，DST 系统必须能够从多轮中 推断出, 这些信息有可能是横跨多个不同的领域的。</p>
</div>
<div class="section" id="multiwoz">
<h2>MultiWOZ 数据集<a class="headerlink" href="#multiwoz" title="Permalink to this headline">¶</a></h2>
<p>多领域数据集 Wizard-of-Oz (<a class="reference external" href="https://www.repository.cam.ac.uk/handle/1810/294507">MultiWOZ</a>) 是一个囊括了 7个领域包含超过10,000个对话的人-人数据集。
原先的 MultiWOZ 2.0 数据集是这篇文章引入的 <a class="bibtex reference internal" href="#nlp-dst-budzianowski2018multiwoz" id="id7">[NLP-DST1]</a>.
然而，在这个教程中我们用数据集 MultiWOZ 2.1  <a class="bibtex reference internal" href="#nlp-dst-eric2019multiwoz" id="id8">[NLP-DST2]</a>, 它 MultiWOZ 2.0 的升级版。它和原先的数据集有固定的一些问题像是状态的错误，语句错误，值规范化的问题等)。我们的模型也可以在 MultiWOZ 2.0 上训练。</p>
<dl class="simple">
<dt>数据集包含下面这些领域:</dt><dd><ol class="arabic simple">
<li><p>restaurant</p></li>
<li><p>hotel</p></li>
<li><p>attraction</p></li>
<li><p>taxi</p></li>
<li><p>train</p></li>
<li><p>hospital</p></li>
<li><p>police.</p></li>
</ol>
</dd>
<dt>和下面这些槽:</dt><dd><ul class="simple">
<li><p>inform (∗)</p></li>
<li><p>address (∗)</p></li>
<li><p>postcode (∗)</p></li>
<li><p>phone (∗)</p></li>
<li><p>name (1234)</p></li>
<li><p>no of choices (1235)</p></li>
<li><p>area (123)</p></li>
<li><p>pricerange (123)</p></li>
<li><p>type (123)</p></li>
<li><p>internet (2)</p></li>
<li><p>parking (2)</p></li>
<li><p>stars (2)</p></li>
<li><p>open hours (3)</p></li>
<li><p>departure (45)</p></li>
<li><p>destination (45)</p></li>
<li><p>leave after (45)</p></li>
<li><p>arrive by (45)</p></li>
<li><p>no of people (1235)</p></li>
<li><p>reference no. (1235)</p></li>
<li><p>trainID (5)</p></li>
<li><p>ticket price (5)</p></li>
<li><p>travel time (5)</p></li>
<li><p>department (7)</p></li>
<li><p>day (1235)</p></li>
<li><p>no of days (123).</p></li>
</ul>
</dd>
</dl>
<p>请注意，一些动作(actions)和槽只和特定领域有关，但一些是全部通用的, 比如，领域无关的。后者用(∗)表示。</p>
<p>MultiWOZ 数据集有 10,438 个对话，总共 115,434 轮。 对话通常分成单和多领域对话。 对话长度分布从 1 到 31，大约 70% 对话有超过 10 轮。 平均轮数是对单领域和多领域分别为 8.93 和 15.39。 </p>
<p>每个对话包括一个目标，多个用户和系统语句以及一个信念状态(belief state)和每轮的对话操作(action)以及相应的槽 另外，每个对话都有一个任务描述。 而且，它包含了系统和用户对话操作(act)的标注 (后者在 MultiWOZ 2.1 中引入).</p>
</div>
<div class="section" id="trade">
<h2>TRADE 模型<a class="headerlink" href="#trade" title="Permalink to this headline">¶</a></h2>
<p><strong>TRA</strong>nsferable <strong>D</strong>ialogue stat<strong>E</strong> generator (TRADE) <a class="bibtex reference internal" href="#nlp-dst-wu2019transferable" id="id10">[NLP-DST4]</a> 是为 多领域面向任务的对话状态追踪问题
特别设计的模型 模型从语句和历史中生成对话状态。它为领域和槽学习嵌入(embeddings)并且 受益于拷贝机制(copy mechanism)从而能够促进领域之间的知识转移。它使得模型能够预测 在给定领域中，训练过程中从未见过的(<strong>领域(domain)</strong>, <strong>槽(slot)</strong>, <strong>值(value)</strong>)三元组。</p>
<div class="figure align-default" id="id20">
<img alt="../_images/dst_trade_architecture.png" src="../_images/dst_trade_architecture.png" />
<p class="caption"><span class="caption-text">Fig. 2: TRADE 模型的架构 (来源: <a class="bibtex reference internal" href="#nlp-dst-wu2019transferable" id="id11">[NLP-DST4]</a>)</span><a class="headerlink" href="#id20" title="Permalink to this image">¶</a></p>
</div>
<p>模型由三个主要部分组成:</p>
<blockquote>
<div><ul class="simple">
<li><p>一个 <strong>语句编码器(utterance encoder)</strong>，</p></li>
<li><p>一个 <strong>槽栅(slot gate)</strong>，以及</p></li>
<li><p>一个 <strong>状态生成器(state generator)</strong>。</p></li>
</ul>
</div></blockquote>
<p><strong>语句编码器(utterance encoder)</strong> 是一个双向 Gated Recurrent Unit (GRU), 返回上下文单词以及 一个编码了整个对话历史的上下文向量。</p>
<p><strong>状态生成器(state generator)</strong> 也用了 GRU 来预测(domain, slot)对的值。生成器用了一个 soft-gated pointer-generator copying，把 <strong>词表上的分布</strong> 和 <strong>对话历史上的分布</strong>
合成一个单独的输出分布。</p>
<p>最后，<strong>槽栅(slot gate)</strong> 是个简单的分类器，把编码器隐状态的上下文向量 映射到三个类上的概率分布: <em>ptr</em>, <em>none</em>,  和 <em>dontcare</em>.</p>
</div>
<div class="section" id="id12">
<h2>数据预处理<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h2>
<p>首先，你需要从 <a class="reference external" href="https://www.repository.cam.ac.uk/handle/1810/294507">MultiWOZ2.1</a> 项目网站上下载 <cite>MULTIWOZ2.1.zip</cite> 。它包含了 MultiWOZ 2.1 数据集。或者，你可以从 <a class="reference external" href="https://www.repository.cam.ac.uk/handle/1810/280608">MultiWOZ2.0</a> 上下载压缩文件 <cite>MULTIWOZ2.zip</cite> 它包含了这个数据集的老版本。</p>
<p>接着我们需要预处理，重新格式化我们的数据集，这会将数据集分成三个分布:</p>
<blockquote>
<div><ul class="simple">
<li><p>traininig split ( <code class="docutils literal notranslate"><span class="pre">train_dials.json</span></code> 文件包含了8242个对话)</p></li>
<li><p>validation split ( <code class="docutils literal notranslate"><span class="pre">val_dials.json</span></code> 文件包含了1000个对话)</p></li>
<li><p>test split (<code class="docutils literal notranslate"><span class="pre">test_dials.json</span></code> 文件包含了999个对话)</p></li>
</ul>
</div></blockquote>
<p>你可以用提供好的 <a class="reference external" href="https://github.com/NVIDIA/NeMo/tree/master/examples/nlp/dialogue_state_tracking/multiwoz/process_multiwoz.py">process_multiwoz.py</a> 脚本
预处理 MultiWOZ 数据集:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> examples/nlp/dialogue_state_tracking/multiwoz
python process_multiwoz.py
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>默认情况下，脚本假设你会把数据拷贝以及解压到 <code class="docutils literal notranslate"><span class="pre">~/data/state_tracking/multiwoz2.1/</span></code> 目录下，并且它会把结果存到 <code class="docutils literal notranslate"><span class="pre">~/data/state_tracking/multiwoz2.1</span></code> 文件夹下 你可以在命令行中传入参数 <code class="docutils literal notranslate"><span class="pre">source_data_dir</span></code> 和 <code class="docutils literal notranslate"><span class="pre">target_data_dir</span></code> 来修改。MultiWOZ 2.0 和 MultiWOZ 2.1 可以用相同的脚本处理。</p>
</div>
</div>
<div class="section" id="nemo">
<h2>构建 NeMo 图<a class="headerlink" href="#nemo" title="Permalink to this headline">¶</a></h2>
<p>NeMo 训练图包括六个模块包括数据层，编码器，解码器和损失函数:</p>
<blockquote>
<div><ul class="simple">
<li><p>data_layer (<code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.collection.nlp.nm.data_layers.MultiWOZDataLayer</span></code>)</p></li>
<li><p>encoder (<code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.backends.pytorch.common.EncoderRNN</span></code>)</p></li>
<li><p>decoder (<code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.collection.nlp.nm.trainables.TRADEGenerator</span></code>)</p></li>
<li><p>gate_loss_fn (<a class="reference internal" href="../collections/core.html#nemo.backends.pytorch.common.losses.CrossEntropyLossNM" title="nemo.backends.pytorch.common.losses.CrossEntropyLossNM"><code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.backends.pytorch.common.losses.CrossEntropyLossNM</span></code></a>)</p></li>
<li><p>ptr_loss_fn (<code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.collections.nlp.nm.losses.MaskedLogLoss</span></code>)</p></li>
<li><p>total_loss_fn (<code class="xref py py-class docutils literal notranslate"><span class="pre">nemo.collection.nlp.nm.losses.LossAggregatorNM</span></code>)</p></li>
</ul>
</div></blockquote>
</div>
<div class="section" id="id13">
<h2>训练<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h2>
<p>想要在数据集 MultiWOZ 2.1 上训练 TRADE 模型的实例，并且在它的测试数据集上进行评估，只需要 用默认参数运行 <a class="reference external" href="https://github.com/NVIDIA/NeMo/tree/master/examples/nlp/dialogue_state_tracking/dialogue_state_tracking_trade.py">dialogue_state_tracking_trade.py</a> :</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> examples/nlp/dialogue_state_tracking
python dialogue_state_tracking_trade.py
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>同样地，这个脚本会默认读取 <code class="docutils literal notranslate"><span class="pre">~/data/state_tracking/multiwoz2.1</span></code> 文件夹.
这个路径可以用 <code class="docutils literal notranslate"><span class="pre">data_dir</span></code> 覆盖。</p>
</div>
</div>
<div class="section" id="id14">
<h2>指标和结果<a class="headerlink" href="#id14" title="Permalink to this headline">¶</a></h2>
<p>在下面的表格中我们比较了我们实现的 TRADE 模型结果和 原始论文 <a class="bibtex reference internal" href="#nlp-dst-wu2019transferable" id="id15">[NLP-DST4]</a> 中的结果。在作者们回复 MultiWOZ 2.0
数据集的结果时候, 我们跑了在 MultiWOZ 2.1 数据集上的原始实现，也记录了这些结果。</p>
<p>我们用了和原始实现中相同的参数。在我们的实现和原始的视线中有些区别。主要的区别是我们的模型没有用预训练的词嵌入，似乎是会影响模型的效果的。 另一个区别是我们在学习策略的时候用了 SquareAnnealing 而不是 固定的学习率。另外，我们是根据训练集创建的词表，而原始实现 是根据所有数据集包括测试和验证集创建的。我们模型的准确率的主要提升是 用了更好的学习率策略。当我们用固定的学习率 我们得到了和原始实现中相似的结果。</p>
<p>我们再模型实现上也做了一些提升来加快训练。这使得我们的实现比原始的实现快很多 另外, NeMo 支持多 GPU 训练，这使得训练时间更快了。 需要注意的是在用多 GPU 的时候学习率应该调高， 因为 batch size 变大了。</p>
<p>根据 <a class="bibtex reference internal" href="#nlp-dst-wu2019transferable" id="id16">[NLP-DST4]</a>, 我们用两个指标来衡量模型的性能:</p>
<blockquote>
<div><ul class="simple">
<li><dl class="simple">
<dt><strong>联合目标准确率(Joint Goal Accuracy)</strong> 比较了每轮对话中的预测对话状态和真实状态，并且输出只有当输出的**所有的值完全正确**</dt><dd><p>才会认为输出是正确的。</p>
</dd>
</dl>
</li>
<li><p><strong>槽准确率(Slot Accuracy)</strong> 独立地比较每个(domain, slot, value)三元组和它的真实值。</p></li>
</ul>
</div></blockquote>
<table class="docutils align-default">
<colgroup>
<col style="width: 41%" />
<col style="width: 7%" />
<col style="width: 7%" />
<col style="width: 7%" />
<col style="width: 7%" />
<col style="width: 7%" />
<col style="width: 7%" />
<col style="width: 7%" />
<col style="width: 7%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head" rowspan="3"><p>TRADE implementations</p></th>
<th class="head" colspan="4"><p>MultiWOZ 2.0</p></th>
<th class="head" colspan="4"><p>MultiWOZ 2.1</p></th>
</tr>
<tr class="row-even"><th class="head" colspan="2"><p>Test</p></th>
<th class="head" colspan="2"><p>Development</p></th>
<th class="head" colspan="2"><p>Test</p></th>
<th class="head" colspan="2"><p>Development</p></th>
</tr>
<tr class="row-odd"><th class="head"><p>Goal</p></th>
<th class="head"><p>Slot</p></th>
<th class="head"><p>Goal</p></th>
<th class="head"><p>Slot</p></th>
<th class="head"><p>Goal</p></th>
<th class="head"><p>Slot</p></th>
<th class="head"><p>Goal</p></th>
<th class="head"><p>Slot</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Original <a class="bibtex reference internal" href="#nlp-dst-wu2019transferable" id="id17">[NLP-DST4]</a></p></td>
<td><p>48.62%</p></td>
<td><p>96.92%</p></td>
<td><p>48.76%</p></td>
<td><p>96.95%</p></td>
<td><p>45.31%</p></td>
<td><p>96.57%</p></td>
<td><p>49.15%</p></td>
<td><p>97.04%</p></td>
</tr>
<tr class="row-odd"><td><p>NeMo’s Implementation of TRADE</p></td>
<td><p>48.92%</p></td>
<td><p>97.03%</p></td>
<td><p>50.96%</p></td>
<td><p>97.17%</p></td>
<td><p>47.25%</p></td>
<td><p>96.80%</p></td>
<td><p>51.38%</p></td>
<td><p>97.21%</p></td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>在训练 TRADE 模型的时候用一个额外的监督信号，强制 Slot Gate 能够恰当的分类 上下文向量。脚本 <a class="reference external" href="https://github.com/NVIDIA/NeMo/tree/master/examples/nlp/dialogue_state_tracking/multiwoz/process_multiwoz.py">process_multiwoz.py</a> 从数据集中抽取额外的信息,
脚本 <a class="reference external" href="https://github.com/NVIDIA/NeMo/tree/master/examples/nlp/dialogue_state_tracking/dialogue_state_tracking_trade.py">dialogue_state_tracking_trade.py</a> 也汇报了 <strong>Gating Accuracy</strong>。</p>
</div>
</div>
<div class="section" id="id18">
<h2>参考<a class="headerlink" href="#id18" title="Permalink to this headline">¶</a></h2>
<p id="bibtex-bibliography-nlp/dialogue_state_tracking_trade-0"><dl class="citation">
<dt class="bibtex label" id="nlp-dst-budzianowski2018multiwoz"><span class="brackets">NLP-DST1</span><span class="fn-backref">(<a href="#id5">1</a>,<a href="#id7">2</a>)</span></dt>
<dd><p>Paweł Budzianowski, Tsung-Hsien Wen, Bo-Hsiang Tseng, Inigo Casanueva, Stefan Ultes, Osman Ramadan, and Milica Gašić. Multiwoz-a large-scale multi-domain wizard-of-oz dataset for task-oriented dialogue modelling. <em>arXiv preprint arXiv:1810.00278</em>, 2018.</p>
</dd>
<dt class="bibtex label" id="nlp-dst-eric2019multiwoz"><span class="brackets"><a class="fn-backref" href="#id8">NLP-DST2</a></span></dt>
<dd><p>Mihail Eric, Rahul Goel, Shachi Paul, Abhishek Sethi, Sanchit Agarwal, Shuyag Gao, and Dilek Hakkani-Tur. Multiwoz 2.1: multi-domain dialogue state corrections and state tracking baselines. <em>arXiv preprint arXiv:1907.01669</em>, 2019.</p>
</dd>
<dt class="bibtex label" id="nlp-dst-henderson2015machine"><span class="brackets"><a class="fn-backref" href="#id3">NLP-DST3</a></span></dt>
<dd><p>Matthew Henderson. Machine learning for dialog state tracking: a review. <em>research.google</em>, 2015.</p>
</dd>
<dt class="bibtex label" id="nlp-dst-wu2019transferable"><span class="brackets">NLP-DST4</span><span class="fn-backref">(<a href="#id4">1</a>,<a href="#id6">2</a>,<a href="#id10">3</a>,<a href="#id11">4</a>,<a href="#id15">5</a>,<a href="#id16">6</a>,<a href="#id17">7</a>)</span></dt>
<dd><p>Chien-Sheng Wu, Andrea Madotto, Ehsan Hosseini-Asl, Caiming Xiong, Richard Socher, and Pascale Fung. Transferable multi-domain state generator for task-oriented dialogue systems. <em>arXiv preprint arXiv:1905.08743</em>, 2019.</p>
</dd>
</dl>
</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="ner.html" class="btn btn-neutral float-right" title="教程" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="transformer_language_model.html" class="btn btn-neutral float-left" title="Transformer语言模型" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018-2020, NVIDIA

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>