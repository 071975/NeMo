{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc4238d8",
   "metadata": {},
   "source": [
    "# Streaming multispeaker ASR and diarization tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa603a94",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1be14c5",
   "metadata": {},
   "source": [
    "Set your NeMo path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c9151c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.insert(0,'/your/path/to/NeMo/')\n",
    "sys.path.insert(0,'/home/taejinp/projects/streaming_mulspk_asr/NeMo')\n",
    "\n",
    "import nemo\n",
    "print(\"Using Nemo PATH:\", nemo.__path__[0])\n",
    "\n",
    "# !pip install gradio==2.9.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbc838c",
   "metadata": {},
   "source": [
    "Set your NeMo path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb24d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo.collections.asr.parts.utils.speaker_utils import audio_rttm_map\n",
    "from nemo.core.config import hydra_runner\n",
    "import gradio as gr\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import hydra\n",
    "import os\n",
    "import torch\n",
    "from streaming_asr_and_diar import (\n",
    "OnlineDiarizer,\n",
    "ASR_DIAR_ONLINE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa5cb01",
   "metadata": {},
   "source": [
    "Read yaml file for online diarization. You have to specifty the following items:\n",
    "    \n",
    "- input manifest file (If  simulation)\n",
    "- VAD model path\n",
    "- Speaker embedding extractor model path\n",
    "- Diarization Decoder model path (Coming soon)\n",
    "- Punctuation model path (automatically download from NGC)\n",
    "- Language model path (Coming soon)\n",
    "\n",
    "Download nemo models and specify the path to config struct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da444302",
   "metadata": {},
   "outputs": [],
   "source": [
    "hydra.initialize(config_path=\"conf\")\n",
    "cfg = hydra.compose(config_name=\"/online_diarization_with_asr.yaml\")\n",
    "import socket\n",
    "print(socket.gethostname())\n",
    "\n",
    "if socket.gethostname() != \"aiapps-06052021\":\n",
    "    # Please download the following models and run the code. \n",
    "\n",
    "    cfg.diarizer.out_dir = \"./streaming_diar_output\"\n",
    "    os.makedirs(cfg.diarizer.out_dir, exist_ok=True)\n",
    "    \n",
    "    # Download CH109 dataset at: https://drive.google.com/drive/folders/1ksq10H-NZbKRfMjEP_WWyBF_G0iAJt6b?usp=sharing\n",
    "    cfg.diarizer.manifest_filepath = \"/your/path/to/ch109.json\"\n",
    "\n",
    "    # Download streaming VAD model at: https://drive.google.com/file/d/1ab42CaYeTkuJSMsMsMLbSS9m5e1isJzx/view?usp=sharing\n",
    "    cfg.diarizer.vad.model_path = \"/your/path/to/mVAD_lin_marblenet-3x2x64-4N-256bs-50e-0.01lr-0.001wd.nemo\"\n",
    "\n",
    "    # Download titanet-m model at: https://drive.google.com/file/d/1xAgjm0udKogPrlQF6cdHLobEKHLY9azA/view?usp=sharing\n",
    "    cfg.diarizer.speaker_embeddings.model_path = \"/your/path/to/titanet-m.nemo\"\n",
    "\n",
    "    # Download Conformer-CTC ASR model at: https://drive.google.com/file/d/1Xg075IbiwL0szI4_a8gYmCPaG1UsgR6E/view?usp=sharing\n",
    "    cfg.diarizer.asr.model_path = \"/your/path/to/Conformer-CTC-BPE_large_Riva_ASR_set_3.0_ep60.nemo\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aa1248",
   "metadata": {},
   "source": [
    "Initialize ASR_DIAR_ONLINE and OnlineDiarizer Class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1fa81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['use_cuda'] = True\n",
    "AUDIO_RTTM_MAP = audio_rttm_map(cfg.diarizer.manifest_filepath)\n",
    "\n",
    "diar = OnlineDiarizer(cfg)\n",
    "\n",
    "diar.uniq_id = \"en_0638\"\n",
    "diar.single_audio_file_path = AUDIO_RTTM_MAP[diar.uniq_id]['audio_filepath']\n",
    "diar.rttm_file_path = AUDIO_RTTM_MAP[diar.uniq_id]['rttm_filepath']\n",
    "# diar.rttm_file_path = None # DER calculation slows down online diarization speed\n",
    "diar._init_segment_variables()\n",
    "\n",
    "asr_diar = ASR_DIAR_ONLINE(diar, cfg=cfg.diarizer, params=params)\n",
    "diar.device = asr_diar.device\n",
    "asr_diar.reset()\n",
    "\n",
    "simulation = True\n",
    "# simulation = False # Run Gradio server with your microphone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5963b9e6",
   "metadata": {},
   "source": [
    "Let's run simulated audio stream to check if streaming system is working properly. After you initiate the following function and while the function is running, you can check the transcription is being generated in realtime.  The path is ./streaming_diar_output/print_script.sh, and this can be viewed using \"streaming_diarization_viewer.ipynb\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c549f35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if simulation:\n",
    "    samplerate, sdata = wavfile.read(diar.single_audio_file_path)\n",
    "    for index in range(int(np.floor(sdata.shape[0]/asr_diar.n_frame_len))):\n",
    "        asr_diar.buffer_counter = index\n",
    "        sample_audio = sdata[asr_diar.CHUNK_SIZE*(asr_diar.buffer_counter):asr_diar.CHUNK_SIZE*(asr_diar.buffer_counter+1)]\n",
    "        asr_diar.callback_sim(sample_audio)\n",
    "else:\n",
    "    isTorch = torch.cuda.is_available()\n",
    "    asr_diar.rttm_file_path = None\n",
    "    iface = gr.Interface(\n",
    "        fn=asr_diar.audio_queue_launcher,\n",
    "        inputs=[\n",
    "            gr.inputs.Audio(source=\"microphone\", type='filepath'), \n",
    "            \"state\",\n",
    "        ],\n",
    "        outputs=[\n",
    "            \"textbox\",\n",
    "            \"state\",\n",
    "        ],\n",
    "        layout=\"horizontal\",\n",
    "        theme=\"huggingface\",\n",
    "        title=f\"NeMo Streaming Conformer CTC Large - English, CUDA:{isTorch}\",\n",
    "        description=\"Demo for English speech recognition using Conformer Transducers\",\n",
    "        allow_flagging='never',\n",
    "        live=True,\n",
    "    )\n",
    "    iface.launch(share=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da436545",
   "metadata": {},
   "source": [
    "Now, go to streaming_diarization_viewer.ipynb and check the realtime output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788550d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
