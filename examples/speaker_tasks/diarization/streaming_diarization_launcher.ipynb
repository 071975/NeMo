{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc4238d8",
   "metadata": {},
   "source": [
    "# Streaming multispeaker ASR and diarization tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa603a94",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1be14c5",
   "metadata": {},
   "source": [
    "Set your NeMo path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4c9151c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Nemo PATH: /home/taejinp/projects/streaming_mulspk_asr/NeMo/nemo\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# sys.path.insert(0,'/your/path/to/NeMo/')\n",
    "sys.path.insert(0,'/home/taejinp/projects/streaming_mulspk_asr/NeMo')\n",
    "\n",
    "import nemo\n",
    "print(\"Using Nemo PATH:\", nemo.__path__[0])\n",
    "\n",
    "# !pip install gradio==2.9.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528e50d1",
   "metadata": {},
   "source": [
    "Set your NeMo path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afb24d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-06-08 16:46:53 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2022-06-08 16:46:56 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-06-08 16:46:56 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "from nemo.collections.asr.parts.utils.speaker_utils import audio_rttm_map\n",
    "from nemo.core.config import hydra_runner\n",
    "import gradio as gr\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import hydra\n",
    "import os\n",
    "import torch\n",
    "from streaming_asr_and_diar import (\n",
    "OnlineDiarizer,\n",
    "ASR_DIAR_ONLINE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa5cb01",
   "metadata": {},
   "source": [
    "Read yaml file for online diarization. You have to specifty the following items:\n",
    "    \n",
    "- input manifest file (If  simulation)\n",
    "- VAD model path\n",
    "- Speaker embedding extractor model path\n",
    "- Diarization Decoder model path (Coming soon)\n",
    "- Punctuation model path (automatically download from NGC)\n",
    "- Language model path (Coming soon)\n",
    "\n",
    "Download nemo models and specify the path to config struct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da444302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aiapps-06052021\n"
     ]
    }
   ],
   "source": [
    "hydra.initialize(config_path=\"conf\")\n",
    "cfg = hydra.compose(config_name=\"/online_diarization_with_asr.yaml\")\n",
    "import socket\n",
    "print(socket.gethostname())\n",
    "\n",
    "if socket.gethostname() != \"aiapps-06052021\":\n",
    "    # Please download the following models and run the code. \n",
    "\n",
    "    cfg.diarizer.out_dir = \"./streaming_diar_output\"\n",
    "    os.makedirs(cfg.diarizer.out_dir, exist_ok=True)\n",
    "    \n",
    "    # Download CH109 dataset at: https://drive.google.com/drive/folders/1ksq10H-NZbKRfMjEP_WWyBF_G0iAJt6b?usp=sharing\n",
    "    cfg.diarizer.manifest_filepath = \"/your/path/to/ch109.json\"\n",
    "\n",
    "    # Download streaming VAD model at: https://drive.google.com/file/d/1ab42CaYeTkuJSMsMsMLbSS9m5e1isJzx/view?usp=sharing\n",
    "    cfg.diarizer.vad.model_path = \"/your/path/to/mVAD_lin_marblenet-3x2x64-4N-256bs-50e-0.01lr-0.001wd.nemo\"\n",
    "\n",
    "    # Download titanet-m model at: https://drive.google.com/file/d/1xAgjm0udKogPrlQF6cdHLobEKHLY9azA/view?usp=sharing\n",
    "    cfg.diarizer.speaker_embeddings.model_path = \"/your/path/to/titanet-m.nemo\"\n",
    "\n",
    "    # Download Conformer-CTC ASR model at: https://drive.google.com/file/d/1Xg075IbiwL0szI4_a8gYmCPaG1UsgR6E/view?usp=sharing\n",
    "    cfg.diarizer.asr.model_path = \"/your/path/to/Conformer-CTC-BPE_large_Riva_ASR_set_3.0_ep60.nemo\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7f9c2f",
   "metadata": {},
   "source": [
    "Initialize ASR_DIAR_ONLINE and OnlineDiarizer Class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc1fa81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-06-08 16:47:33 speaker_utils:81] Number of files to diarize: 109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-06-08 16:47:33 modelPT:148] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - background\n",
      "    - speech\n",
      "    batch_size: 256\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      shift:\n",
      "        prob: 0.5\n",
      "        min_shift_ms: -10.0\n",
      "        max_shift_ms: 10.0\n",
      "      white_noise:\n",
      "        prob: 0.5\n",
      "        min_level: -90\n",
      "        max_level: -46\n",
      "        norm: true\n",
      "      noise:\n",
      "        prob: 0.5\n",
      "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 30\n",
      "        max_gain_db: 300.0\n",
      "        norm: true\n",
      "      gain:\n",
      "        prob: 0.5\n",
      "        min_gain_dbfs: -10.0\n",
      "        max_gain_dbfs: 10.0\n",
      "        norm: true\n",
      "    num_workers: 16\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2022-06-08 16:47:33 modelPT:155] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - background\n",
      "    - speech\n",
      "    batch_size: 256\n",
      "    shuffle: false\n",
      "    val_loss_idx: 0\n",
      "    num_workers: 16\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2022-06-08 16:47:33 modelPT:161] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - background\n",
      "    - speech\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    test_loss_idx: 0\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-06-08 16:47:33 features:200] PADDING: 16\n",
      "[NeMo I 2022-06-08 16:47:33 save_restore_connector:243] Model EncDecClassificationModel was successfully restored from /home/taejinp/gdrive/model/VAD_models/mVAD_lin_marblenet-3x2x64-4N-256bs-50e-0.01lr-0.001wd.nemo.\n",
      "[NeMo I 2022-06-08 16:47:33 clustering_diarizer:122] VAD model loaded locally from /home/taejinp/gdrive/model/VAD_models/mVAD_lin_marblenet-3x2x64-4N-256bs-50e-0.01lr-0.001wd.nemo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-06-08 16:47:33 modelPT:148] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    time_length: 3\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /manifests/noise/rir_noise_manifest.json\n",
      "        prob: 0.5\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 15\n",
      "      speed:\n",
      "        prob: 0.5\n",
      "        sr: 16000\n",
      "        resample_type: kaiser_fast\n",
      "        min_speed_rate: 0.95\n",
      "        max_speed_rate: 1.05\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2022-06-08 16:47:33 modelPT:155] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    time_length: 3\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-06-08 16:47:33 features:200] PADDING: 16\n",
      "[NeMo I 2022-06-08 16:47:34 label_models:100] loss is Angular Softmax\n",
      "[NeMo I 2022-06-08 16:47:34 save_restore_connector:243] Model EncDecSpeakerLabelModel was successfully restored from /home/taejinp/Downloads/titanet-m.nemo.\n",
      "[NeMo I 2022-06-08 16:47:34 clustering_diarizer:143] Speaker Model restored locally from /home/taejinp/Downloads/titanet-m.nemo\n",
      "[NeMo I 2022-06-08 16:47:34 streaming_asr_and_diar:335] Setting online diarization buffer to : 100\n",
      "[NeMo I 2022-06-08 16:47:34 streaming_asr_and_diar:345] Setting online diarization buffer to : 100\n",
      "[NeMo I 2022-06-08 16:47:34 speaker_utils:81] Number of files to diarize: 109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-06-08 16:47:34 modelPT:148] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - background\n",
      "    - speech\n",
      "    batch_size: 256\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      shift:\n",
      "        prob: 0.5\n",
      "        min_shift_ms: -10.0\n",
      "        max_shift_ms: 10.0\n",
      "      white_noise:\n",
      "        prob: 0.5\n",
      "        min_level: -90\n",
      "        max_level: -46\n",
      "        norm: true\n",
      "      noise:\n",
      "        prob: 0.5\n",
      "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 30\n",
      "        max_gain_db: 300.0\n",
      "        norm: true\n",
      "      gain:\n",
      "        prob: 0.5\n",
      "        min_gain_dbfs: -10.0\n",
      "        max_gain_dbfs: 10.0\n",
      "        norm: true\n",
      "    num_workers: 16\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2022-06-08 16:47:34 modelPT:155] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - background\n",
      "    - speech\n",
      "    batch_size: 256\n",
      "    shuffle: false\n",
      "    val_loss_idx: 0\n",
      "    num_workers: 16\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2022-06-08 16:47:34 modelPT:161] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - background\n",
      "    - speech\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    test_loss_idx: 0\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-06-08 16:47:34 features:200] PADDING: 16\n",
      "[NeMo I 2022-06-08 16:47:34 save_restore_connector:243] Model EncDecClassificationModel was successfully restored from /home/taejinp/gdrive/model/VAD_models/mVAD_lin_marblenet-3x2x64-4N-256bs-50e-0.01lr-0.001wd.nemo.\n",
      "[NeMo I 2022-06-08 16:47:37 mixins:166] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-06-08 16:47:37 modelPT:148] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /data/asr_datasets_prebuilt/RIVA_ASR_SET_3.0_tarred/tarred_audio_manifest.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    is_tarred: true\n",
      "    tarred_audio_filepaths: /data/asr_datasets_prebuilt/RIVA_ASR_SET_3.0_tarred/audio__OP_0..4095_CL_.tar\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20.0\n",
      "    min_duration: 0.1\n",
      "    shuffle_n: 1024\n",
      "    num_workers: 16\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2022-06-08 16:47:37 modelPT:155] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /data/Jasper_NEMO_manifests/librivox-test-other.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    use_start_end_token: false\n",
      "    num_workers: 16\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2022-06-08 16:47:37 modelPT:161] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-06-08 16:47:37 features:200] PADDING: 0\n",
      "[NeMo I 2022-06-08 16:47:39 save_restore_connector:243] Model EncDecCTCModelBPE was successfully restored from /home/taejinp/gdrive/model/ASR_models/Conformer-CTC-BPE_large_Riva_ASR_set_3.0_ep60.nemo.\n",
      "[NeMo I 2022-06-08 16:47:39 features:200] PADDING: 0\n",
      "[NeMo I 2022-06-08 16:47:39 features:200] PADDING: 0\n",
      "[NeMo I 2022-06-08 16:47:39 features:200] PADDING: 0\n",
      "[NeMo I 2022-06-08 16:47:39 cloud:56] Found existing object /home/taejinp/.cache/torch/NeMo/NeMo_1.10.0rc0/punctuation_en_distilbert/613c4ee780c6fc158f49d3566cbd6636/punctuation_en_distilbert.nemo.\n",
      "[NeMo I 2022-06-08 16:47:39 cloud:62] Re-using file from: /home/taejinp/.cache/torch/NeMo/NeMo_1.10.0rc0/punctuation_en_distilbert/613c4ee780c6fc158f49d3566cbd6636/punctuation_en_distilbert.nemo\n",
      "[NeMo I 2022-06-08 16:47:39 common:789] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2022-06-08 16:47:40 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: distilbert-base-uncased, vocab_file: /tmp/tmpqf8ltc95/tokenizer.vocab_file, merges_files: None, special_tokens_dict: {}, and use_fast: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using eos_token, but it is not set yet.\n",
      "Using bos_token, but it is not set yet.\n",
      "[NeMo W 2022-06-08 16:47:42 modelPT:215] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n",
      "[NeMo W 2022-06-08 16:47:42 modelPT:148] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    use_tarred_dataset: false\n",
      "    label_info_save_dir: null\n",
      "    text_file: text_train.txt\n",
      "    labels_file: labels_train.txt\n",
      "    tokens_in_batch: null\n",
      "    max_seq_length: 128\n",
      "    num_samples: -1\n",
      "    use_cache: true\n",
      "    cache_dir: null\n",
      "    get_label_frequences: false\n",
      "    verbose: true\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    tar_shuffle_n: 1\n",
      "    shuffle: true\n",
      "    drop_last: false\n",
      "    pin_memory: true\n",
      "    num_workers: 8\n",
      "    persistent_workers: true\n",
      "    ds_item: punct_dataset_complete\n",
      "    \n",
      "[NeMo W 2022-06-08 16:47:42 modelPT:155] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    use_tarred_dataset: false\n",
      "    label_info_save_dir: null\n",
      "    text_file: text_dev.txt\n",
      "    labels_file: labels_dev.txt\n",
      "    tokens_in_batch: null\n",
      "    max_seq_length: 128\n",
      "    num_samples: -1\n",
      "    use_cache: true\n",
      "    cache_dir: null\n",
      "    get_label_frequences: false\n",
      "    verbose: true\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    tar_shuffle_n: 1\n",
      "    shuffle: true\n",
      "    drop_last: false\n",
      "    pin_memory: true\n",
      "    num_workers: 8\n",
      "    persistent_workers: true\n",
      "    ds_item: punct_dataset_complete\n",
      "    \n",
      "[NeMo W 2022-06-08 16:47:42 modelPT:161] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    use_tarred_dataset: false\n",
      "    label_info_save_dir: null\n",
      "    text_file: text_dev.txt\n",
      "    labels_file: labels_dev.txt\n",
      "    tokens_in_batch: null\n",
      "    max_seq_length: 128\n",
      "    num_samples: -1\n",
      "    use_cache: true\n",
      "    cache_dir: null\n",
      "    get_label_frequences: false\n",
      "    verbose: true\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    tar_shuffle_n: 1\n",
      "    shuffle: true\n",
      "    drop_last: false\n",
      "    pin_memory: true\n",
      "    num_workers: 8\n",
      "    persistent_workers: true\n",
      "    ds_item: punct_dataset_complete\n",
      "    \n",
      "[NeMo W 2022-06-08 16:47:42 nlp_overrides:223] Apex was not found. Please see the NeMo README for installation instructions: https://github.com/NVIDIA/apex\n",
      "    Megatron-based models require Apex to function correctly.\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertEncoder: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[NeMo W 2022-06-08 16:47:44 punctuation_capitalization_model:668] The artifact `class_labels.punct_labels_file` was not found in checkpoint. Will rely on `punct_label_ids` parameter\n",
      "[NeMo W 2022-06-08 16:47:44 punctuation_capitalization_model:690] The artifact `class_labels.capit_labels_file` was not found in checkpoint. Will rely on `capit_label_ids` parameter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-06-08 16:47:44 save_restore_connector:243] Model PunctuationCapitalizationModel was successfully restored from /home/taejinp/.cache/torch/NeMo/NeMo_1.10.0rc0/punctuation_en_distilbert/613c4ee780c6fc158f49d3566cbd6636/punctuation_en_distilbert.nemo.\n"
     ]
    }
   ],
   "source": [
    "params = {}\n",
    "params['use_cuda'] = True\n",
    "AUDIO_RTTM_MAP = audio_rttm_map(cfg.diarizer.manifest_filepath)\n",
    "\n",
    "diar = OnlineDiarizer(cfg)\n",
    "\n",
    "diar.uniq_id = \"en_0638\"\n",
    "diar.single_audio_file_path = AUDIO_RTTM_MAP[diar.uniq_id]['audio_filepath']\n",
    "diar.rttm_file_path = AUDIO_RTTM_MAP[diar.uniq_id]['rttm_filepath']\n",
    "# diar.rttm_file_path = None # DER calculation slows down online diarization speed\n",
    "diar._init_segment_variables()\n",
    "\n",
    "asr_diar = ASR_DIAR_ONLINE(diar, cfg=cfg.diarizer, params=params)\n",
    "diar.device = asr_diar.device\n",
    "asr_diar.reset()\n",
    "\n",
    "simulation = True\n",
    "# simulation = False # Run Gradio server with your microphone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e29e8c",
   "metadata": {},
   "source": [
    "Let's run simulated audio stream to check if streaming system is working properly. After you initiate the following function and while the function is running, you can check the transcription is being generated in realtime.  The path is ./streaming_diar_output/print_script.sh, and this can be viewed using \"streaming_diarization_viewer.ipynb\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c549f35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-06-08 16:55:28 streaming_asr_and_diar:123] 52.55ms 'read_audio_file_and_return_samples'\n",
      "[NeMo I 2022-06-08 16:55:28 streaming_asr_and_diar:123] 54.31ms '_run_VAD_decoder'\n",
      "[NeMo I 2022-06-08 16:55:28 streaming_asr_and_diar:123] 1.36ms 'read_audio_file_and_return_samples'\n",
      "[NeMo I 2022-06-08 16:55:28 streaming_asr_and_diar:123] 33.93ms '_run_ASR_decoder'\n",
      "[NeMo I 2022-06-08 16:55:28 streaming_asr_and_diar:123] 0.03ms 'get_VAD_from_ASR'\n",
      "[NeMo I 2022-06-08 16:55:28 streaming_asr_and_diar:123] 79.07ms '_extract_speaker_embeddings'\n",
      "total_segments_processed_count:  283\n",
      "hist_curr_boundary: 183\n",
      "self.history_buffer_seg_end: 183\n",
      "[NeMo I 2022-06-08 16:55:28 streaming_asr_and_diar:123] 3.33ms 'getReducedMat'\n",
      "Scanning p_value: 2, est_num_of_spk: 1 g_p 325431.125\n",
      "Scanning p_value: 4, est_num_of_spk: 2 g_p 1.5550446510314941\n",
      "Scanning p_value: 7, est_num_of_spk: 2 g_p 1.212620735168457\n",
      "Scanning p_value: 9, est_num_of_spk: 2 g_p 1.2389185428619385\n",
      "Scanning p_value: 12, est_num_of_spk: 2 g_p 1.1658473014831543\n",
      "Scanning p_value: 14, est_num_of_spk: 2 g_p 1.217933177947998\n",
      "Scanning p_value: 17, est_num_of_spk: 2 g_p 1.2323249578475952\n",
      "Scanning p_value: 19, est_num_of_spk: 2 g_p 1.2589596509933472\n",
      "Scanning p_value: 22, est_num_of_spk: 2 g_p 1.2913234233856201\n",
      "Scanning p_value: 24, est_num_of_spk: 2 g_p 1.2786989212036133\n",
      "Scanning p_value: 27, est_num_of_spk: 2 g_p 1.2558751106262207\n",
      "Scanning p_value: 29, est_num_of_spk: 2 g_p 1.261618733406067\n",
      "Scanning p_value: 32, est_num_of_spk: 2 g_p 1.2583112716674805\n",
      "Scanning p_value: 34, est_num_of_spk: 2 g_p 1.2785444259643555\n",
      "Scanning p_value: 37, est_num_of_spk: 2 g_p 1.2891430854797363\n",
      "Scanning p_value: 39, est_num_of_spk: 2 g_p 1.2832057476043701\n",
      "Scanning p_value: 42, est_num_of_spk: 2 g_p 1.2863008975982666\n",
      "Scanning p_value: 44, est_num_of_spk: 2 g_p 1.2935686111450195\n",
      "Scanning p_value: 47, est_num_of_spk: 2 g_p 1.3330622911453247\n",
      "Scanning p_value: 50, est_num_of_spk: 2 g_p 1.3476155996322632\n",
      "p_value_stat:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2])\n",
      "num _spks bincount: tensor([0, 3])\n",
      "spk_counting_buffer_size: 3\n",
      "emb ssize:  torch.Size([200, 192]) 21\n",
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:123] 1.61ms 'matchNewOldclusterLabels'\n",
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:123] 533.65ms 'online_diarization'\n",
      "[NeMo I 2022-06-08 16:55:29 punctuation_capitalization_model:1057] Using batch size 1 for inference\n",
      "[NeMo I 2022-06-08 16:55:29 punctuation_capitalization_infer_dataset:91] Max length: 11\n",
      "[NeMo I 2022-06-08 16:55:29 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-06-08 16:55:29 data_preprocessing:406] Min: 9 |                  Max: 9 |                  Mean: 9.0 |                  Median: 9.0\n",
      "[NeMo I 2022-06-08 16:55:29 data_preprocessing:412] 75 percentile: 9.00\n",
      "[NeMo I 2022-06-08 16:55:29 data_preprocessing:413] 99 percentile: 9.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 116.00batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After  Punctuation: ['hu,', 'Yeah,', \"that's\", 'good', 'for', 'and', 'I']\n",
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:123] 17.93ms 'punctuate_words'\n",
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:639] Streaming Diar [en_0638][frame-    190th    ]: DER:0.1959 MISS:0.0585 FA:0.1072, CER:0.0301\n",
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:123] 84.84ms 'print_online_DER_info'\n",
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:123] 1.55ms 'read_audio_file_and_return_samples'\n",
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:123] 3.22ms '_run_VAD_decoder'\n",
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:123] 3.00ms 'read_audio_file_and_return_samples'\n",
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:123] 52.33ms '_run_ASR_decoder'\n",
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:123] 0.04ms 'get_VAD_from_ASR'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:123] 80.22ms '_extract_speaker_embeddings'\n",
      "total_segments_processed_count:  283\n",
      "hist_curr_boundary: 183\n",
      "self.history_buffer_seg_end: 183\n",
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:123] 1.81ms 'getReducedMat'\n",
      "p_value_stat:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2])\n",
      "num _spks bincount: tensor([0, 3])\n",
      "spk_counting_buffer_size: 3\n",
      "emb ssize:  torch.Size([200, 192]) 21\n",
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:123] 0.95ms 'matchNewOldclusterLabels'\n",
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:123] 139.90ms 'online_diarization'\n",
      "[NeMo I 2022-06-08 16:55:29 punctuation_capitalization_model:1057] Using batch size 1 for inference\n",
      "[NeMo I 2022-06-08 16:55:29 punctuation_capitalization_infer_dataset:91] Max length: 11\n",
      "[NeMo I 2022-06-08 16:55:29 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-06-08 16:55:29 data_preprocessing:406] Min: 9 |                  Max: 9 |                  Mean: 9.0 |                  Median: 9.0\n",
      "[NeMo I 2022-06-08 16:55:29 data_preprocessing:412] 75 percentile: 9.00\n",
      "[NeMo I 2022-06-08 16:55:29 data_preprocessing:413] 99 percentile: 9.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 81.44batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After  Punctuation: ['good,', 'Yeah,', \"that's\", 'good', 'for', 'and', 'I']\n",
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:123] 20.53ms 'punctuate_words'\n",
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:639] Streaming Diar [en_0638][frame-    191th    ]: DER:0.1959 MISS:0.0585 FA:0.1072, CER:0.0301\n",
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:123] 69.69ms 'print_online_DER_info'\n",
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:123] 2.85ms 'read_audio_file_and_return_samples'\n",
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:123] 3.95ms '_run_VAD_decoder'\n",
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:123] 2.91ms 'read_audio_file_and_return_samples'\n",
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:123] 54.43ms '_run_ASR_decoder'\n",
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:123] 0.05ms 'get_VAD_from_ASR'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:123] 66.33ms '_extract_speaker_embeddings'\n",
      "total_segments_processed_count:  287\n",
      "hist_curr_boundary: 187\n",
      "self.history_buffer_seg_end: 187\n",
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:123] 2.32ms 'getReducedMat'\n",
      "p_value_stat:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2])\n",
      "num _spks bincount: tensor([0, 3])\n",
      "spk_counting_buffer_size: 3\n",
      "emb ssize:  torch.Size([200, 192]) 21\n",
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:123] 0.94ms 'matchNewOldclusterLabels'\n",
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:123] 128.91ms 'online_diarization'\n",
      "[NeMo I 2022-06-08 16:55:29 punctuation_capitalization_model:1057] Using batch size 1 for inference\n",
      "[NeMo I 2022-06-08 16:55:29 punctuation_capitalization_infer_dataset:91] Max length: 10\n",
      "[NeMo I 2022-06-08 16:55:29 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-06-08 16:55:29 data_preprocessing:406] Min: 8 |                  Max: 8 |                  Mean: 8.0 |                  Median: 8.0\n",
      "[NeMo I 2022-06-08 16:55:29 data_preprocessing:412] 75 percentile: 8.00\n",
      "[NeMo I 2022-06-08 16:55:29 data_preprocessing:413] 99 percentile: 8.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 84.29batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After  Punctuation: ['good,', 'me', 'and', 'I', 'already', 'got', 'another', 'apartment']\n",
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:123] 23.91ms 'punctuate_words'\n",
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:639] Streaming Diar [en_0638][frame-    192th    ]: DER:0.2007 MISS:0.0581 FA:0.1077, CER:0.0348\n",
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:123] 72.51ms 'print_online_DER_info'\n",
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:123] 2.91ms 'read_audio_file_and_return_samples'\n",
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:123] 3.99ms '_run_VAD_decoder'\n",
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:123] 2.72ms 'read_audio_file_and_return_samples'\n",
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:123] 42.42ms '_run_ASR_decoder'\n",
      "[NeMo I 2022-06-08 16:55:29 streaming_asr_and_diar:123] 0.04ms 'get_VAD_from_ASR'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 75.81ms '_extract_speaker_embeddings'\n",
      "total_segments_processed_count:  289\n",
      "hist_curr_boundary: 189\n",
      "self.history_buffer_seg_end: 189\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 2.33ms 'getReducedMat'\n",
      "p_value_stat:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2])\n",
      "num _spks bincount: tensor([0, 3])\n",
      "spk_counting_buffer_size: 3\n",
      "emb ssize:  torch.Size([200, 192]) 21\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 0.95ms 'matchNewOldclusterLabels'\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 137.20ms 'online_diarization'\n",
      "[NeMo I 2022-06-08 16:55:30 punctuation_capitalization_model:1057] Using batch size 1 for inference\n",
      "[NeMo I 2022-06-08 16:55:30 punctuation_capitalization_infer_dataset:91] Max length: 12\n",
      "[NeMo I 2022-06-08 16:55:30 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-06-08 16:55:30 data_preprocessing:406] Min: 10 |                  Max: 10 |                  Mean: 10.0 |                  Median: 10.0\n",
      "[NeMo I 2022-06-08 16:55:30 data_preprocessing:412] 75 percentile: 10.00\n",
      "[NeMo I 2022-06-08 16:55:30 data_preprocessing:413] 99 percentile: 10.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 125.48batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After  Punctuation: ['i,', 'I', 'already', 'got', 'another', 'apartment', 'for', 'when', 'I', 'moved']\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 16.42ms 'punctuate_words'\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:639] Streaming Diar [en_0638][frame-    193th    ]: DER:0.1986 MISS:0.0575 FA:0.1066, CER:0.0345\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 84.41ms 'print_online_DER_info'\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 2.91ms 'read_audio_file_and_return_samples'\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 3.98ms '_run_VAD_decoder'\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 2.96ms 'read_audio_file_and_return_samples'\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 43.46ms '_run_ASR_decoder'\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 0.10ms 'get_VAD_from_ASR'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 86.70ms '_extract_speaker_embeddings'\n",
      "total_segments_processed_count:  290\n",
      "hist_curr_boundary: 190\n",
      "self.history_buffer_seg_end: 190\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 3.69ms 'getReducedMat'\n",
      "p_value_stat:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2])\n",
      "num _spks bincount: tensor([0, 3])\n",
      "spk_counting_buffer_size: 3\n",
      "emb ssize:  torch.Size([200, 192]) 21\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 0.93ms 'matchNewOldclusterLabels'\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 153.69ms 'online_diarization'\n",
      "[NeMo I 2022-06-08 16:55:30 punctuation_capitalization_model:1057] Using batch size 1 for inference\n",
      "[NeMo I 2022-06-08 16:55:30 punctuation_capitalization_infer_dataset:91] Max length: 10\n",
      "[NeMo I 2022-06-08 16:55:30 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-06-08 16:55:30 data_preprocessing:406] Min: 8 |                  Max: 8 |                  Mean: 8.0 |                  Median: 8.0\n",
      "[NeMo I 2022-06-08 16:55:30 data_preprocessing:412] 75 percentile: 8.00\n",
      "[NeMo I 2022-06-08 16:55:30 data_preprocessing:413] 99 percentile: 8.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 143.74batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After  Punctuation: ['got', 'another', 'apartment', 'for', 'when', 'I', 'move', 'out']\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 14.80ms 'punctuate_words'\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:639] Streaming Diar [en_0638][frame-    194th    ]: DER:0.1982 MISS:0.0574 FA:0.1064, CER:0.0344\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 71.37ms 'print_online_DER_info'\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 2.72ms 'read_audio_file_and_return_samples'\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 3.85ms '_run_VAD_decoder'\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 2.65ms 'read_audio_file_and_return_samples'\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 43.66ms '_run_ASR_decoder'\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 0.06ms 'get_VAD_from_ASR'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 85.84ms '_extract_speaker_embeddings'\n",
      "total_segments_processed_count:  292\n",
      "hist_curr_boundary: 192\n",
      "self.history_buffer_seg_end: 192\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 3.34ms 'getReducedMat'\n",
      "p_value_stat:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2])\n",
      "num _spks bincount: tensor([0, 3])\n",
      "spk_counting_buffer_size: 3\n",
      "emb ssize:  torch.Size([200, 192]) 21\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 1.13ms 'matchNewOldclusterLabels'\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 155.99ms 'online_diarization'\n",
      "[NeMo I 2022-06-08 16:55:30 punctuation_capitalization_model:1057] Using batch size 1 for inference\n",
      "[NeMo I 2022-06-08 16:55:30 punctuation_capitalization_infer_dataset:91] Max length: 12\n",
      "[NeMo I 2022-06-08 16:55:30 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-06-08 16:55:30 data_preprocessing:406] Min: 10 |                  Max: 10 |                  Mean: 10.0 |                  Median: 10.0\n",
      "[NeMo I 2022-06-08 16:55:30 data_preprocessing:412] 75 percentile: 10.00\n",
      "[NeMo I 2022-06-08 16:55:30 data_preprocessing:413] 99 percentile: 10.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 155.22batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After  Punctuation: ['apartment', 'for', 'when', 'I', 'move', 'out,', 'Oh,', 'you,', 'did,', 'yeah?']\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 14.38ms 'punctuate_words'\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:639] Streaming Diar [en_0638][frame-    195th    ]: DER:0.2022 MISS:0.0570 FA:0.1065, CER:0.0387\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 72.53ms 'print_online_DER_info'\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 1.53ms 'read_audio_file_and_return_samples'\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 2.80ms '_run_VAD_decoder'\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 1.48ms 'read_audio_file_and_return_samples'\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 34.41ms '_run_ASR_decoder'\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 0.04ms 'get_VAD_from_ASR'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 64.72ms '_extract_speaker_embeddings'\n",
      "total_segments_processed_count:  295\n",
      "hist_curr_boundary: 195\n",
      "self.history_buffer_seg_end: 195\n",
      "[NeMo I 2022-06-08 16:55:30 streaming_asr_and_diar:123] 2.25ms 'getReducedMat'\n",
      "p_value_stat:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2])\n",
      "num _spks bincount: tensor([0, 3])\n",
      "spk_counting_buffer_size: 3\n",
      "emb ssize:  torch.Size([200, 192]) 21\n",
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:123] 1.54ms 'matchNewOldclusterLabels'\n",
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:123] 138.72ms 'online_diarization'\n",
      "[NeMo I 2022-06-08 16:55:31 punctuation_capitalization_model:1057] Using batch size 1 for inference\n",
      "[NeMo I 2022-06-08 16:55:31 punctuation_capitalization_infer_dataset:91] Max length: 10\n",
      "[NeMo I 2022-06-08 16:55:31 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-06-08 16:55:31 data_preprocessing:406] Min: 8 |                  Max: 8 |                  Mean: 8.0 |                  Median: 8.0\n",
      "[NeMo I 2022-06-08 16:55:31 data_preprocessing:412] 75 percentile: 8.00\n",
      "[NeMo I 2022-06-08 16:55:31 data_preprocessing:413] 99 percentile: 8.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 96.68batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After  Punctuation: ['moved', 'out.', 'Oh,', 'you', 'did,', 'Yeah,', 'where', 'if?']\n",
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:123] 21.93ms 'punctuate_words'\n",
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:639] Streaming Diar [en_0638][frame-    196th    ]: DER:0.2090 MISS:0.0565 FA:0.1056, CER:0.0469\n",
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:123] 82.15ms 'print_online_DER_info'\n",
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:123] 3.17ms 'read_audio_file_and_return_samples'\n",
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:123] 5.43ms '_run_VAD_decoder'\n",
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:123] 3.03ms 'read_audio_file_and_return_samples'\n",
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:123] 46.19ms '_run_ASR_decoder'\n",
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:123] 0.04ms 'get_VAD_from_ASR'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:123] 66.12ms '_extract_speaker_embeddings'\n",
      "total_segments_processed_count:  297\n",
      "hist_curr_boundary: 197\n",
      "self.history_buffer_seg_end: 197\n",
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:123] 2.24ms 'getReducedMat'\n",
      "p_value_stat:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2])\n",
      "num _spks bincount: tensor([0, 3])\n",
      "spk_counting_buffer_size: 3\n",
      "emb ssize:  torch.Size([200, 192]) 21\n",
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:123] 1.16ms 'matchNewOldclusterLabels'\n",
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:123] 167.44ms 'online_diarization'\n",
      "[NeMo I 2022-06-08 16:55:31 punctuation_capitalization_model:1057] Using batch size 1 for inference\n",
      "[NeMo I 2022-06-08 16:55:31 punctuation_capitalization_infer_dataset:91] Max length: 13\n",
      "[NeMo I 2022-06-08 16:55:31 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-06-08 16:55:31 data_preprocessing:406] Min: 11 |                  Max: 11 |                  Mean: 11.0 |                  Median: 11.0\n",
      "[NeMo I 2022-06-08 16:55:31 data_preprocessing:412] 75 percentile: 11.00\n",
      "[NeMo I 2022-06-08 16:55:31 data_preprocessing:413] 99 percentile: 11.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 171.20batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After  Punctuation: ['you', 'did?', 'yeah.', 'where', \"it's\", 'on', 'the', 'corner', 'of']\n",
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:123] 13.22ms 'punctuate_words'\n",
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:639] Streaming Diar [en_0638][frame-    197th    ]: DER:0.2115 MISS:0.0563 FA:0.1051, CER:0.0500\n",
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:123] 74.34ms 'print_online_DER_info'\n",
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:123] 1.52ms 'read_audio_file_and_return_samples'\n",
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:123] 2.71ms '_run_VAD_decoder'\n",
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:123] 1.30ms 'read_audio_file_and_return_samples'\n",
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:123] 42.59ms '_run_ASR_decoder'\n",
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:123] 0.04ms 'get_VAD_from_ASR'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:123] 65.18ms '_extract_speaker_embeddings'\n",
      "total_segments_processed_count:  299\n",
      "hist_curr_boundary: 199\n",
      "self.history_buffer_seg_end: 199\n",
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:123] 2.27ms 'getReducedMat'\n",
      "p_value_stat:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2])\n",
      "num _spks bincount: tensor([0, 3])\n",
      "spk_counting_buffer_size: 3\n",
      "emb ssize:  torch.Size([200, 192]) 21\n",
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:123] 0.96ms 'matchNewOldclusterLabels'\n",
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:123] 126.71ms 'online_diarization'\n",
      "[NeMo I 2022-06-08 16:55:31 punctuation_capitalization_model:1057] Using batch size 1 for inference\n",
      "[NeMo I 2022-06-08 16:55:31 punctuation_capitalization_infer_dataset:91] Max length: 13\n",
      "[NeMo I 2022-06-08 16:55:31 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-06-08 16:55:31 data_preprocessing:406] Min: 11 |                  Max: 11 |                  Mean: 11.0 |                  Median: 11.0\n",
      "[NeMo I 2022-06-08 16:55:31 data_preprocessing:412] 75 percentile: 11.00\n",
      "[NeMo I 2022-06-08 16:55:31 data_preprocessing:413] 99 percentile: 11.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 87.68batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After  Punctuation: ['yeah,', 'where', \"it's\", 'on', 'the', 'corner', 'of', 'Columbia', 'and']\n",
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:123] 19.70ms 'punctuate_words'\n",
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:639] Streaming Diar [en_0638][frame-    198th    ]: DER:0.2161 MISS:0.0563 FA:0.1098, CER:0.0500\n",
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:123] 109.00ms 'print_online_DER_info'\n",
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:123] 2.95ms 'read_audio_file_and_return_samples'\n",
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:123] 3.90ms '_run_VAD_decoder'\n",
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:123] 1.83ms 'read_audio_file_and_return_samples'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:123] 40.40ms '_run_ASR_decoder'\n",
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:123] 0.03ms 'get_VAD_from_ASR'\n",
      "[NeMo I 2022-06-08 16:55:31 streaming_asr_and_diar:123] 65.97ms '_extract_speaker_embeddings'\n",
      "total_segments_processed_count:  300\n",
      "hist_curr_boundary: 200\n",
      "self.history_buffer_seg_end: 200\n",
      "[NeMo I 2022-06-08 16:55:32 streaming_asr_and_diar:123] 2.13ms 'getReducedMat'\n",
      "p_value_stat:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2])\n",
      "num _spks bincount: tensor([0, 3])\n",
      "spk_counting_buffer_size: 3\n",
      "emb ssize:  torch.Size([200, 192]) 21\n",
      "[NeMo I 2022-06-08 16:55:32 streaming_asr_and_diar:123] 1.70ms 'matchNewOldclusterLabels'\n",
      "[NeMo I 2022-06-08 16:55:32 streaming_asr_and_diar:123] 133.35ms 'online_diarization'\n",
      "[NeMo I 2022-06-08 16:55:32 punctuation_capitalization_model:1057] Using batch size 1 for inference\n",
      "[NeMo I 2022-06-08 16:55:32 punctuation_capitalization_infer_dataset:91] Max length: 13\n",
      "[NeMo I 2022-06-08 16:55:32 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-06-08 16:55:32 data_preprocessing:406] Min: 11 |                  Max: 11 |                  Mean: 11.0 |                  Median: 11.0\n",
      "[NeMo I 2022-06-08 16:55:32 data_preprocessing:412] 75 percentile: 11.00\n",
      "[NeMo I 2022-06-08 16:55:32 data_preprocessing:413] 99 percentile: 11.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 138.03batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After  Punctuation: [\"it's\", 'on', 'the', 'corner', 'of', 'Columbia', 'and', 'Kal']\n",
      "[NeMo I 2022-06-08 16:55:32 streaming_asr_and_diar:123] 15.86ms 'punctuate_words'\n",
      "[NeMo I 2022-06-08 16:55:32 streaming_asr_and_diar:639] Streaming Diar [en_0638][frame-    199th    ]: DER:0.2183 MISS:0.0563 FA:0.1120, CER:0.0500\n",
      "[NeMo I 2022-06-08 16:55:32 streaming_asr_and_diar:123] 74.88ms 'print_online_DER_info'\n",
      "[NeMo I 2022-06-08 16:55:32 streaming_asr_and_diar:123] 1.53ms 'read_audio_file_and_return_samples'\n",
      "[NeMo I 2022-06-08 16:55:32 streaming_asr_and_diar:123] 2.66ms '_run_VAD_decoder'\n",
      "[NeMo I 2022-06-08 16:55:32 streaming_asr_and_diar:123] 1.31ms 'read_audio_file_and_return_samples'\n",
      "[NeMo I 2022-06-08 16:55:32 streaming_asr_and_diar:123] 32.68ms '_run_ASR_decoder'\n",
      "[NeMo I 2022-06-08 16:55:32 streaming_asr_and_diar:123] 0.12ms 'get_VAD_from_ASR'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-06-08 16:55:32 streaming_asr_and_diar:123] 80.96ms '_extract_speaker_embeddings'\n",
      "total_segments_processed_count:  303\n",
      "hist_curr_boundary: 203\n",
      "self.history_buffer_seg_end: 203\n",
      "[NeMo I 2022-06-08 16:55:32 streaming_asr_and_diar:123] 2.46ms 'getReducedMat'\n",
      "Scanning p_value: 2, est_num_of_spk: 1 g_p 67648.140625\n",
      "Scanning p_value: 4, est_num_of_spk: 2 g_p 1.4774346351623535\n",
      "Scanning p_value: 7, est_num_of_spk: 2 g_p 1.3408901691436768\n",
      "Scanning p_value: 9, est_num_of_spk: 2 g_p 1.222879409790039\n",
      "Scanning p_value: 12, est_num_of_spk: 2 g_p 1.2530797719955444\n",
      "Scanning p_value: 14, est_num_of_spk: 2 g_p 1.2535674571990967\n",
      "Scanning p_value: 17, est_num_of_spk: 2 g_p 1.2571723461151123\n",
      "Scanning p_value: 19, est_num_of_spk: 2 g_p 1.2742434740066528\n",
      "Scanning p_value: 22, est_num_of_spk: 2 g_p 1.3157317638397217\n",
      "Scanning p_value: 24, est_num_of_spk: 2 g_p 1.3258529901504517\n",
      "Scanning p_value: 27, est_num_of_spk: 2 g_p 1.347334861755371\n",
      "Scanning p_value: 29, est_num_of_spk: 2 g_p 1.3212518692016602\n",
      "Scanning p_value: 32, est_num_of_spk: 2 g_p 1.3777636289596558\n",
      "Scanning p_value: 34, est_num_of_spk: 2 g_p 1.4115852117538452\n",
      "Scanning p_value: 37, est_num_of_spk: 2 g_p 1.453660011291504\n",
      "Scanning p_value: 39, est_num_of_spk: 2 g_p 1.4818174839019775\n",
      "Scanning p_value: 42, est_num_of_spk: 2 g_p 1.5433446168899536\n",
      "Scanning p_value: 44, est_num_of_spk: 2 g_p 1.5998985767364502\n",
      "Scanning p_value: 47, est_num_of_spk: 2 g_p 1.6578149795532227\n",
      "Scanning p_value: 50, est_num_of_spk: 2 g_p 1.6929165124893188\n",
      "p_value_stat:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1])\n",
      "num _spks bincount: tensor([0, 3])\n",
      "spk_counting_buffer_size: 3\n",
      "emb ssize:  torch.Size([200, 192]) 21\n",
      "[NeMo I 2022-06-08 16:55:32 streaming_asr_and_diar:123] 0.97ms 'matchNewOldclusterLabels'\n",
      "[NeMo I 2022-06-08 16:55:32 streaming_asr_and_diar:123] 494.91ms 'online_diarization'\n",
      "[NeMo I 2022-06-08 16:55:32 punctuation_capitalization_model:1057] Using batch size 1 for inference\n",
      "[NeMo I 2022-06-08 16:55:32 punctuation_capitalization_infer_dataset:91] Max length: 12\n",
      "[NeMo I 2022-06-08 16:55:32 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-06-08 16:55:32 data_preprocessing:406] Min: 10 |                  Max: 10 |                  Mean: 10.0 |                  Median: 10.0\n",
      "[NeMo I 2022-06-08 16:55:32 data_preprocessing:412] 75 percentile: 10.00\n",
      "[NeMo I 2022-06-08 16:55:32 data_preprocessing:413] 99 percentile: 10.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 87.73batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After  Punctuation: ['of', 'Columbia', 'and', 'coal,', 'Uh,', 'Hu,', 'and', \"it's\"]\n",
      "[NeMo I 2022-06-08 16:55:32 streaming_asr_and_diar:123] 21.52ms 'punctuate_words'\n",
      "[NeMo I 2022-06-08 16:55:32 streaming_asr_and_diar:639] Streaming Diar [en_0638][frame-    200th    ]: DER:0.2244 MISS:0.0554 FA:0.1103, CER:0.0587\n",
      "[NeMo I 2022-06-08 16:55:32 streaming_asr_and_diar:123] 76.65ms 'print_online_DER_info'\n",
      "[NeMo I 2022-06-08 16:55:32 streaming_asr_and_diar:123] 1.63ms 'read_audio_file_and_return_samples'\n",
      "[NeMo I 2022-06-08 16:55:32 streaming_asr_and_diar:123] 3.02ms '_run_VAD_decoder'\n",
      "[NeMo I 2022-06-08 16:55:32 streaming_asr_and_diar:123] 3.82ms 'read_audio_file_and_return_samples'\n",
      "[NeMo I 2022-06-08 16:55:32 streaming_asr_and_diar:123] 47.57ms '_run_ASR_decoder'\n",
      "[NeMo I 2022-06-08 16:55:32 streaming_asr_and_diar:123] 0.12ms 'get_VAD_from_ASR'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-06-08 16:55:32 streaming_asr_and_diar:123] 79.70ms '_extract_speaker_embeddings'\n",
      "total_segments_processed_count:  305\n",
      "hist_curr_boundary: 205\n",
      "self.history_buffer_seg_end: 205\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:123] 2.29ms 'getReducedMat'\n",
      "p_value_stat:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1])\n",
      "num _spks bincount: tensor([0, 3])\n",
      "spk_counting_buffer_size: 3\n",
      "emb ssize:  torch.Size([200, 192]) 21\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:123] 0.94ms 'matchNewOldclusterLabels'\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:123] 143.20ms 'online_diarization'\n",
      "[NeMo I 2022-06-08 16:55:33 punctuation_capitalization_model:1057] Using batch size 1 for inference\n",
      "[NeMo I 2022-06-08 16:55:33 punctuation_capitalization_infer_dataset:91] Max length: 14\n",
      "[NeMo I 2022-06-08 16:55:33 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-06-08 16:55:33 data_preprocessing:406] Min: 12 |                  Max: 12 |                  Mean: 12.0 |                  Median: 12.0\n",
      "[NeMo I 2022-06-08 16:55:33 data_preprocessing:412] 75 percentile: 12.00\n",
      "[NeMo I 2022-06-08 16:55:33 data_preprocessing:413] 99 percentile: 12.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 118.00batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After  Punctuation: ['kal', 'uhhuh', 'and', \"it's\", 'one', 'bedroom', 'and']\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:123] 18.17ms 'punctuate_words'\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:639] Streaming Diar [en_0638][frame-    201th    ]: DER:0.2236 MISS:0.0551 FA:0.1102, CER:0.0583\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:123] 77.57ms 'print_online_DER_info'\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:123] 2.88ms 'read_audio_file_and_return_samples'\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:123] 4.51ms '_run_VAD_decoder'\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:123] 2.72ms 'read_audio_file_and_return_samples'\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:123] 44.49ms '_run_ASR_decoder'\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:123] 0.03ms 'get_VAD_from_ASR'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:123] 64.78ms '_extract_speaker_embeddings'\n",
      "total_segments_processed_count:  305\n",
      "hist_curr_boundary: 205\n",
      "self.history_buffer_seg_end: 205\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:123] 2.64ms 'getReducedMat'\n",
      "p_value_stat:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1])\n",
      "num _spks bincount: tensor([0, 3])\n",
      "spk_counting_buffer_size: 3\n",
      "emb ssize:  torch.Size([200, 192]) 21\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:123] 1.00ms 'matchNewOldclusterLabels'\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:123] 132.36ms 'online_diarization'\n",
      "[NeMo I 2022-06-08 16:55:33 punctuation_capitalization_model:1057] Using batch size 1 for inference\n",
      "[NeMo I 2022-06-08 16:55:33 punctuation_capitalization_infer_dataset:91] Max length: 12\n",
      "[NeMo I 2022-06-08 16:55:33 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-06-08 16:55:33 data_preprocessing:406] Min: 10 |                  Max: 10 |                  Mean: 10.0 |                  Median: 10.0\n",
      "[NeMo I 2022-06-08 16:55:33 data_preprocessing:412] 75 percentile: 10.00\n",
      "[NeMo I 2022-06-08 16:55:33 data_preprocessing:413] 99 percentile: 10.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 115.05batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After  Punctuation: ['coal', 'and', \"it's\", 'one', 'bedroom,', 'and', 'so', 'I']\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:123] 18.49ms 'punctuate_words'\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:639] Streaming Diar [en_0638][frame-    202th    ]: DER:0.2236 MISS:0.0551 FA:0.1102, CER:0.0583\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:123] 82.40ms 'print_online_DER_info'\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:123] 1.52ms 'read_audio_file_and_return_samples'\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:123] 2.90ms '_run_VAD_decoder'\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:123] 3.02ms 'read_audio_file_and_return_samples'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:123] 60.87ms '_run_ASR_decoder'\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:123] 0.09ms 'get_VAD_from_ASR'\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:123] 68.02ms '_extract_speaker_embeddings'\n",
      "total_segments_processed_count:  307\n",
      "hist_curr_boundary: 207\n",
      "self.history_buffer_seg_end: 207\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:123] 2.31ms 'getReducedMat'\n",
      "p_value_stat:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1])\n",
      "num _spks bincount: tensor([0, 3])\n",
      "spk_counting_buffer_size: 3\n",
      "emb ssize:  torch.Size([200, 192]) 21\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:123] 0.99ms 'matchNewOldclusterLabels'\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:123] 130.47ms 'online_diarization'\n",
      "[NeMo I 2022-06-08 16:55:33 punctuation_capitalization_model:1057] Using batch size 1 for inference\n",
      "[NeMo I 2022-06-08 16:55:33 punctuation_capitalization_infer_dataset:91] Max length: 16\n",
      "[NeMo I 2022-06-08 16:55:33 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-06-08 16:55:33 data_preprocessing:406] Min: 14 |                  Max: 14 |                  Mean: 14.0 |                  Median: 14.0\n",
      "[NeMo I 2022-06-08 16:55:33 data_preprocessing:412] 75 percentile: 14.00\n",
      "[NeMo I 2022-06-08 16:55:33 data_preprocessing:413] 99 percentile: 14.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 133.15batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After  Punctuation: [\"it's\", 'a', 'one', 'bedroom,', 'and', 'so', 'I', 'have', 'to', 'put', 'down', 'like']\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:123] 17.63ms 'punctuate_words'\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:639] Streaming Diar [en_0638][frame-    203th    ]: DER:0.2231 MISS:0.0594 FA:0.1085, CER:0.0551\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:123] 76.05ms 'print_online_DER_info'\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:123] 1.42ms 'read_audio_file_and_return_samples'\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:123] 2.44ms '_run_VAD_decoder'\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:123] 1.29ms 'read_audio_file_and_return_samples'\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:123] 33.80ms '_run_ASR_decoder'\n",
      "[NeMo I 2022-06-08 16:55:33 streaming_asr_and_diar:123] 0.04ms 'get_VAD_from_ASR'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-51e21b2b3d9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0masr_diar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msample_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0masr_diar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHUNK_SIZE\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masr_diar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer_counter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0masr_diar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHUNK_SIZE\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masr_diar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer_counter\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0masr_diar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_audio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0misTorch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/streaming_mulspk_asr/NeMo/examples/speaker_tasks/diarization/streaming_asr_and_diar.py\u001b[0m in \u001b[0;36mcallback_sim\u001b[0;34m(self, sample_audio)\u001b[0m\n\u001b[1;32m   1762\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_audio\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1763\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1764\u001b[0;31m         \u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_diar_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranscribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_audio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer_start\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred_diar_labels\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpred_diar_labels\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1766\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimestamps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/streaming_mulspk_asr/NeMo/examples/speaker_tasks/diarization/streaming_asr_and_diar.py\u001b[0m in \u001b[0;36mtranscribe\u001b[0;34m(self, frame, merge)\u001b[0m\n\u001b[1;32m   1796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1797\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1798\u001b[0;31m         \u001b[0mpred_diar_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monline_diarization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvad_ts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1800\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/streaming_mulspk_asr/NeMo/examples/speaker_tasks/diarization/streaming_asr_and_diar.py\u001b[0m in \u001b[0;36mtimed\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtimed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0mte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'log_time'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/streaming_mulspk_asr/NeMo/examples/speaker_tasks/diarization/streaming_asr_and_diar.py\u001b[0m in \u001b[0;36monline_diarization\u001b[0;34m(self, asr_diar, vad_ts)\u001b[0m\n\u001b[1;32m   1088\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m             \u001b[0;31m# Extract speaker embeddings from the subsegment timestamps.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m             embeddings = asr_diar._extract_speaker_embeddings(shift, \n\u001b[0m\u001b[1;32m   1091\u001b[0m                                                               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membs_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniq_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscale_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m                                                               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegment_raw_audio_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniq_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscale_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/streaming_mulspk_asr/NeMo/examples/speaker_tasks/diarization/streaming_asr_and_diar.py\u001b[0m in \u001b[0;36mtimed\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtimed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0mte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'log_time'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/streaming_mulspk_asr/NeMo/examples/speaker_tasks/diarization/streaming_asr_and_diar.py\u001b[0m in \u001b[0;36m_extract_speaker_embeddings\u001b[0;34m(self, hop, embs_array, audio_signal, segment_ranges, online_extraction)\u001b[0m\n\u001b[1;32m   1395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1397\u001b[0;31m                 \u001b[0mtorch_embs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_embedding_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_signal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1398\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0membs_array\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m                     \u001b[0membs_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_embs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/streaming_mulspk_asr/NeMo/examples/speaker_tasks/diarization/streaming_asr_and_diar.py\u001b[0m in \u001b[0;36m_run_embedding_extractor\u001b[0;34m(self, audio_signal)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_embedding_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maudio_signal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m         \u001b[0mtorch_audio_signal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch_audio_signal_lens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_torch_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_signal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m         _, torch_embs = self.diar._speaker_model.forward(input_signal=torch_audio_signal, \n\u001b[0m\u001b[1;32m   1360\u001b[0m                                                          input_signal_length=torch_audio_signal_lens)\n\u001b[1;32m   1361\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch_embs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/streaming_mulspk_asr/NeMo/nemo/core/classes/common.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0;31m# Call the method - this can be forward, or any other callable method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m         instance._attach_and_validate_output_types(\n",
      "\u001b[0;32m~/projects/streaming_mulspk_asr/NeMo/nemo/collections/asr/models/label_models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_signal, input_signal_length)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0mencoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_signal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocessed_signal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocessed_signal_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/streaming_mulspk_asr/NeMo/nemo/core/classes/common.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, wrapped, instance, args, kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m         \u001b[0;31m# Call the method - this can be forward, or any other callable method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m         instance._attach_and_validate_output_types(\n",
      "\u001b[0;32m~/projects/streaming_mulspk_asr/NeMo/nemo/collections/asr/modules/conv_asr.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, encoder_output, length)\u001b[0m\n\u001b[1;32m    862\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtypecheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m         \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m         \u001b[0membs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/streaming_mulspk_asr/NeMo/nemo/collections/asr/parts/submodules/tdnn_attention.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, length)\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlens_to_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;31m# encoder statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/streaming_mulspk_asr/NeMo/nemo/collections/asr/parts/submodules/tdnn_attention.py\u001b[0m in \u001b[0;36mlens_to_mask\u001b[0;34m(lens, max_len, device)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mnum_values\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msum\u001b[0m \u001b[0mof\u001b[0m \u001b[0mmask\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0museful\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcomputing\u001b[0m \u001b[0mstatistics\u001b[0m \u001b[0mlater\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \"\"\"\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mlens_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlens_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if simulation:\n",
    "    samplerate, sdata = wavfile.read(diar.single_audio_file_path)\n",
    "    for index in range(int(np.floor(sdata.shape[0]/asr_diar.n_frame_len))):\n",
    "        asr_diar.buffer_counter = index\n",
    "        sample_audio = sdata[asr_diar.CHUNK_SIZE*(asr_diar.buffer_counter):asr_diar.CHUNK_SIZE*(asr_diar.buffer_counter+1)]\n",
    "        asr_diar.callback_sim(sample_audio)\n",
    "else:\n",
    "    isTorch = torch.cuda.is_available()\n",
    "    asr_diar.rttm_file_path = None\n",
    "    iface = gr.Interface(\n",
    "        fn=asr_diar.audio_queue_launcher,\n",
    "        inputs=[\n",
    "            gr.inputs.Audio(source=\"microphone\", type='filepath'), \n",
    "            \"state\",\n",
    "        ],\n",
    "        outputs=[\n",
    "            \"textbox\",\n",
    "            \"state\",\n",
    "        ],\n",
    "        layout=\"horizontal\",\n",
    "        theme=\"huggingface\",\n",
    "        title=f\"NeMo Streaming Conformer CTC Large - English, CUDA:{isTorch}\",\n",
    "        description=\"Demo for English speech recognition using Conformer Transducers\",\n",
    "        allow_flagging='never',\n",
    "        live=True,\n",
    "    )\n",
    "    iface.launch(share=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f58d0a",
   "metadata": {},
   "source": [
    "Now, go to streaming_diarization_viewer.ipynb and check the realtime output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c945be1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
