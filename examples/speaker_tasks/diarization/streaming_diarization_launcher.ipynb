{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc4238d8",
   "metadata": {},
   "source": [
    "# Streaming multispeaker ASR and diarization tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa603a94",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1be14c5",
   "metadata": {},
   "source": [
    "Set your NeMo path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4c9151c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Nemo PATH: /home/taejinp/projects/streaming_mulspk_asr/NeMo/nemo\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# sys.path.insert(0,'/your/path/to/NeMo/')\n",
    "sys.path.insert(0,'/home/taejinp/projects/streaming_mulspk_asr/NeMo')\n",
    "\n",
    "import nemo\n",
    "print(\"Using Nemo PATH:\", nemo.__path__[0])\n",
    "\n",
    "# !pip install gradio==2.9.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbc838c",
   "metadata": {},
   "source": [
    "Set your NeMo path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afb24d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-06-15 16:21:03 optimizers:55] Apex was not found. Using the lamb or fused_adam optimizer will error out.\n",
      "[NeMo W 2022-06-15 16:21:06 experimental:27] Module <class 'nemo.collections.nlp.data.language_modeling.megatron.megatron_batch_samplers.MegatronPretrainingRandomBatchSampler'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo W 2022-06-15 16:21:06 experimental:27] Module <class 'nemo.collections.nlp.models.text_normalization_as_tagging.thutmose_tagger.ThutmoseTaggerModel'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "from nemo.collections.asr.parts.utils.speaker_utils import audio_rttm_map\n",
    "from nemo.core.config import hydra_runner\n",
    "import gradio as gr\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import hydra\n",
    "import os\n",
    "import torch\n",
    "from streaming_asr_and_diar import (\n",
    "OnlineDiarizer,\n",
    "ASR_DIAR_ONLINE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa5cb01",
   "metadata": {},
   "source": [
    "Read yaml file for online diarization. You have to specifty the following items:\n",
    "    \n",
    "- input manifest file (If  simulation)\n",
    "- VAD model path\n",
    "- Speaker embedding extractor model path\n",
    "- Diarization Decoder model path (Coming soon)\n",
    "- Punctuation model path (automatically download from NGC)\n",
    "- Language model path (Coming soon)\n",
    "\n",
    "Download nemo models and specify the path to config struct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da444302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aiapps-06052021\n"
     ]
    }
   ],
   "source": [
    "hydra.initialize(config_path=\"conf\")\n",
    "cfg = hydra.compose(config_name=\"/online_diarization_with_asr_demo_setup.yaml\")\n",
    "import socket\n",
    "print(socket.gethostname())\n",
    "\n",
    "if socket.gethostname() != \"aiapps-06052021\":\n",
    "    # Please download the following models and run the code. \n",
    "\n",
    "    cfg.diarizer.out_dir = \"./streaming_diar_output\"\n",
    "    os.makedirs(cfg.diarizer.out_dir, exist_ok=True)\n",
    "    \n",
    "    # Download CH109 dataset at: https://drive.google.com/drive/folders/1ksq10H-NZbKRfMjEP_WWyBF_G0iAJt6b?usp=sharing\n",
    "    cfg.diarizer.manifest_filepath = \"/your/path/to/ch109.json\"\n",
    "\n",
    "    # Download streaming VAD model at: https://drive.google.com/file/d/1ab42CaYeTkuJSMsMsMLbSS9m5e1isJzx/view?usp=sharing\n",
    "    cfg.diarizer.vad.model_path = \"/your/path/to/mVAD_lin_marblenet-3x2x64-4N-256bs-50e-0.01lr-0.001wd.nemo\"\n",
    "\n",
    "    # Download titanet-m model at: https://drive.google.com/file/d/1xAgjm0udKogPrlQF6cdHLobEKHLY9azA/view?usp=sharing\n",
    "    cfg.diarizer.speaker_embeddings.model_path = \"/your/path/to/titanet-m.nemo\"\n",
    "\n",
    "    # Download Conformer-CTC ASR model at: https://drive.google.com/file/d/1Xg075IbiwL0szI4_a8gYmCPaG1UsgR6E/view?usp=sharing\n",
    "    cfg.diarizer.asr.model_path = \"/your/path/to/Conformer-CTC-BPE_large_Riva_ASR_set_3.0_ep60.nemo\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aa1248",
   "metadata": {},
   "source": [
    "Initialize ASR_DIAR_ONLINE and OnlineDiarizer Class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc1fa81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-06-15 16:21:15 speaker_utils:81] Number of files to diarize: 109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-06-15 16:21:15 modelPT:148] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - background\n",
      "    - speech\n",
      "    batch_size: 256\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      shift:\n",
      "        prob: 0.5\n",
      "        min_shift_ms: -10.0\n",
      "        max_shift_ms: 10.0\n",
      "      white_noise:\n",
      "        prob: 0.5\n",
      "        min_level: -90\n",
      "        max_level: -46\n",
      "        norm: true\n",
      "      noise:\n",
      "        prob: 0.5\n",
      "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 30\n",
      "        max_gain_db: 300.0\n",
      "        norm: true\n",
      "      gain:\n",
      "        prob: 0.5\n",
      "        min_gain_dbfs: -10.0\n",
      "        max_gain_dbfs: 10.0\n",
      "        norm: true\n",
      "    num_workers: 16\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2022-06-15 16:21:15 modelPT:155] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - background\n",
      "    - speech\n",
      "    batch_size: 256\n",
      "    shuffle: false\n",
      "    val_loss_idx: 0\n",
      "    num_workers: 16\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2022-06-15 16:21:15 modelPT:161] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - background\n",
      "    - speech\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    test_loss_idx: 0\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-06-15 16:21:15 features:200] PADDING: 16\n",
      "[NeMo I 2022-06-15 16:21:19 save_restore_connector:243] Model EncDecClassificationModel was successfully restored from /home/taejinp/gdrive/model/VAD_models/mVAD_lin_marblenet-3x2x64-4N-256bs-50e-0.01lr-0.001wd.nemo.\n",
      "[NeMo I 2022-06-15 16:21:19 clustering_diarizer:122] VAD model loaded locally from /home/taejinp/gdrive/model/VAD_models/mVAD_lin_marblenet-3x2x64-4N-256bs-50e-0.01lr-0.001wd.nemo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-06-15 16:21:20 modelPT:148] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    time_length: 3\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /manifests/noise/rir_noise_manifest.json\n",
      "        prob: 0.5\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 15\n",
      "      speed:\n",
      "        prob: 0.5\n",
      "        sr: 16000\n",
      "        resample_type: kaiser_fast\n",
      "        min_speed_rate: 0.95\n",
      "        max_speed_rate: 1.05\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2022-06-15 16:21:20 modelPT:155] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    time_length: 3\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-06-15 16:21:20 features:200] PADDING: 16\n",
      "[NeMo I 2022-06-15 16:21:20 label_models:100] loss is Angular Softmax\n",
      "[NeMo I 2022-06-15 16:21:20 save_restore_connector:243] Model EncDecSpeakerLabelModel was successfully restored from /home/taejinp/Downloads/titanet-m.nemo.\n",
      "[NeMo I 2022-06-15 16:21:20 clustering_diarizer:143] Speaker Model restored locally from /home/taejinp/Downloads/titanet-m.nemo\n",
      "[NeMo I 2022-06-15 16:21:20 speaker_utils:81] Number of files to diarize: 109\n",
      "[NeMo I 2022-06-15 16:21:20 streaming_asr_and_diar:360] Setting online diarization buffer to : 100\n",
      "[NeMo I 2022-06-15 16:21:20 streaming_asr_and_diar:370] Setting online diarization buffer to : 150\n",
      "[NeMo I 2022-06-15 16:21:20 speaker_utils:81] Number of files to diarize: 109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-06-15 16:21:20 modelPT:148] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - background\n",
      "    - speech\n",
      "    batch_size: 256\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      shift:\n",
      "        prob: 0.5\n",
      "        min_shift_ms: -10.0\n",
      "        max_shift_ms: 10.0\n",
      "      white_noise:\n",
      "        prob: 0.5\n",
      "        min_level: -90\n",
      "        max_level: -46\n",
      "        norm: true\n",
      "      noise:\n",
      "        prob: 0.5\n",
      "        manifest_path: /manifests/noise_0_1_musan_fs.json\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 30\n",
      "        max_gain_db: 300.0\n",
      "        norm: true\n",
      "      gain:\n",
      "        prob: 0.5\n",
      "        min_gain_dbfs: -10.0\n",
      "        max_gain_dbfs: 10.0\n",
      "        norm: true\n",
      "    num_workers: 16\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2022-06-15 16:21:20 modelPT:155] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - background\n",
      "    - speech\n",
      "    batch_size: 256\n",
      "    shuffle: false\n",
      "    val_loss_idx: 0\n",
      "    num_workers: 16\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2022-06-15 16:21:20 modelPT:161] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    labels:\n",
      "    - background\n",
      "    - speech\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    test_loss_idx: 0\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-06-15 16:21:20 features:200] PADDING: 16\n",
      "[NeMo I 2022-06-15 16:21:20 save_restore_connector:243] Model EncDecClassificationModel was successfully restored from /home/taejinp/gdrive/model/VAD_models/mVAD_lin_marblenet-3x2x64-4N-256bs-50e-0.01lr-0.001wd.nemo.\n",
      "[NeMo I 2022-06-15 16:21:23 mixins:166] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-06-15 16:21:24 modelPT:148] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /data/asr_datasets_prebuilt/RIVA_ASR_SET_3.0_tarred/tarred_audio_manifest.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: true\n",
      "    is_tarred: true\n",
      "    tarred_audio_filepaths: /data/asr_datasets_prebuilt/RIVA_ASR_SET_3.0_tarred/audio__OP_0..4095_CL_.tar\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20.0\n",
      "    min_duration: 0.1\n",
      "    shuffle_n: 1024\n",
      "    num_workers: 16\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2022-06-15 16:21:24 modelPT:155] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /data/Jasper_NEMO_manifests/librivox-test-other.json\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    use_start_end_token: false\n",
      "    num_workers: 16\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2022-06-15 16:21:24 modelPT:161] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-06-15 16:21:24 features:200] PADDING: 0\n",
      "[NeMo I 2022-06-15 16:21:25 save_restore_connector:243] Model EncDecCTCModelBPE was successfully restored from /home/taejinp/gdrive/model/ASR_models/Conformer-CTC-BPE_large_Riva_ASR_set_3.0_ep60.nemo.\n",
      "[NeMo I 2022-06-15 16:21:25 features:200] PADDING: 0\n",
      "[NeMo I 2022-06-15 16:21:25 features:200] PADDING: 0\n",
      "[NeMo I 2022-06-15 16:21:25 features:200] PADDING: 0\n",
      "[NeMo I 2022-06-15 16:21:27 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: distilbert-base-uncased, vocab_file: /tmp/tmp0lm5r_8z/tokenizer.vocab_file, merges_files: None, special_tokens_dict: {}, and use_fast: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using eos_token, but it is not set yet.\n",
      "Using bos_token, but it is not set yet.\n",
      "[NeMo W 2022-06-15 16:21:30 modelPT:215] You tried to register an artifact under config key=tokenizer.vocab_file but an artifact for it has already been registered.\n",
      "[NeMo W 2022-06-15 16:21:30 modelPT:148] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    use_tarred_dataset: false\n",
      "    label_info_save_dir: null\n",
      "    text_file: text_train.txt\n",
      "    labels_file: labels_train.txt\n",
      "    tokens_in_batch: null\n",
      "    max_seq_length: 128\n",
      "    num_samples: -1\n",
      "    use_cache: true\n",
      "    cache_dir: null\n",
      "    get_label_frequences: false\n",
      "    verbose: true\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    tar_shuffle_n: 1\n",
      "    shuffle: true\n",
      "    drop_last: false\n",
      "    pin_memory: true\n",
      "    num_workers: 8\n",
      "    persistent_workers: true\n",
      "    ds_item: punct_dataset_complete\n",
      "    \n",
      "[NeMo W 2022-06-15 16:21:30 modelPT:155] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    use_tarred_dataset: false\n",
      "    label_info_save_dir: null\n",
      "    text_file: text_dev.txt\n",
      "    labels_file: labels_dev.txt\n",
      "    tokens_in_batch: null\n",
      "    max_seq_length: 128\n",
      "    num_samples: -1\n",
      "    use_cache: true\n",
      "    cache_dir: null\n",
      "    get_label_frequences: false\n",
      "    verbose: true\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    tar_shuffle_n: 1\n",
      "    shuffle: true\n",
      "    drop_last: false\n",
      "    pin_memory: true\n",
      "    num_workers: 8\n",
      "    persistent_workers: true\n",
      "    ds_item: punct_dataset_complete\n",
      "    \n",
      "[NeMo W 2022-06-15 16:21:30 modelPT:161] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    use_tarred_dataset: false\n",
      "    label_info_save_dir: null\n",
      "    text_file: text_dev.txt\n",
      "    labels_file: labels_dev.txt\n",
      "    tokens_in_batch: null\n",
      "    max_seq_length: 128\n",
      "    num_samples: -1\n",
      "    use_cache: true\n",
      "    cache_dir: null\n",
      "    get_label_frequences: false\n",
      "    verbose: true\n",
      "    n_jobs: 0\n",
      "    tar_metadata_file: null\n",
      "    tar_shuffle_n: 1\n",
      "    shuffle: true\n",
      "    drop_last: false\n",
      "    pin_memory: true\n",
      "    num_workers: 8\n",
      "    persistent_workers: true\n",
      "    ds_item: punct_dataset_complete\n",
      "    \n",
      "[NeMo W 2022-06-15 16:21:30 nlp_overrides:223] Apex was not found. Please see the NeMo README for installation instructions: https://github.com/NVIDIA/apex\n",
      "    Megatron-based models require Apex to function correctly.\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertEncoder: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[NeMo W 2022-06-15 16:21:32 punctuation_capitalization_model:668] The artifact `class_labels.punct_labels_file` was not found in checkpoint. Will rely on `punct_label_ids` parameter\n",
      "[NeMo W 2022-06-15 16:21:32 punctuation_capitalization_model:690] The artifact `class_labels.capit_labels_file` was not found in checkpoint. Will rely on `capit_label_ids` parameter\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-06-15 16:21:32 save_restore_connector:243] Model PunctuationCapitalizationModel was successfully restored from /home/taejinp/gdrive/model/language_model/punctuation_en_distilbert.nemo.\n"
     ]
    }
   ],
   "source": [
    "params = {}\n",
    "params['use_cuda'] = True\n",
    "AUDIO_RTTM_MAP = audio_rttm_map(cfg.diarizer.manifest_filepath)\n",
    "\n",
    "diar = OnlineDiarizer(cfg)\n",
    "\n",
    "diar.uniq_id = \"en_0638\"\n",
    "diar.single_audio_file_path = AUDIO_RTTM_MAP[diar.uniq_id]['audio_filepath']\n",
    "diar.rttm_file_path = AUDIO_RTTM_MAP[diar.uniq_id]['rttm_filepath']\n",
    "# diar.rttm_file_path = None # DER calculation slows down online diarization speed\n",
    "diar._init_segment_variables()\n",
    "\n",
    "asr_diar = ASR_DIAR_ONLINE(diar, cfg=cfg.diarizer)\n",
    "diar.device = asr_diar.device\n",
    "asr_diar.reset()\n",
    "\n",
    "simulation = True\n",
    "# simulation = False # Run Gradio server with your microphone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5963b9e6",
   "metadata": {},
   "source": [
    "Let's run simulated audio stream to check if streaming system is working properly. After you initiate the following function and while the function is running, you can check the transcription is being generated in realtime.  The path is ./streaming_diar_output/print_script.sh, and this can be viewed using \"streaming_diarization_viewer.ipynb\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788550d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import uniform\n",
    "import time\n",
    "# from rich.jupyter import jprint\n",
    "import os\n",
    "from IPython.display import display, clear_output\n",
    "OUTPUT_DIR=\"/home/taejinp/projects/run_time/streaming_diar_output_univ\"\n",
    "i=0\n",
    "while True:\n",
    "    clear_output(wait=True)\n",
    "    fp = open(f'{OUTPUT_DIR}/print_script.sh','r').read()\n",
    "    print(str(i)+'\\n'+fp)\n",
    "    time.sleep(0.2)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c549f35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion embedding _emb shape: torch.Size([144, 192])\n",
      "Reduced embedding emb shape: (144, 192)\n",
      "p_value_stat:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2])\n",
      "num _spks bincount: tensor([0, 0, 0, 0, 0, 6])\n",
      "spk_counting_buffer_size: 6\n",
      "emb ssize:  torch.Size([144, 192]) 6\n",
      "sigs list: 53 segment_ranges: 53 segment_indexes: 53\n",
      "sigs list: 60 segment_ranges: 60 segment_indexes: 60\n",
      "sigs list: 70 segment_ranges: 70 segment_indexes: 70\n",
      "sigs list: 83 segment_ranges: 83 segment_indexes: 83\n",
      "sigs list: 144 segment_ranges: 144 segment_indexes: 144\n",
      "[NeMo I 2022-06-15 16:34:20 punctuation_capitalization_model:1057] Using batch size 1 for inference\n",
      "[NeMo I 2022-06-15 16:34:20 punctuation_capitalization_infer_dataset:91] Max length: 11\n",
      "[NeMo I 2022-06-15 16:34:20 data_preprocessing:404] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-06-15 16:34:20 data_preprocessing:406] Min: 9 |                  Max: 9 |                  Mean: 9.0 |                  Median: 9.0\n",
      "[NeMo I 2022-06-15 16:34:20 data_preprocessing:412] 75 percentile: 9.00\n",
      "[NeMo I 2022-06-15 16:34:20 data_preprocessing:413] 99 percentile: 9.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 122.75batch/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-51e21b2b3d9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0masr_diar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msample_audio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0masr_diar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHUNK_SIZE\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masr_diar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer_counter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0masr_diar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHUNK_SIZE\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masr_diar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer_counter\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0masr_diar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_audio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0misTorch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/streaming_mulspk_asr/NeMo/examples/speaker_tasks/diarization/streaming_asr_and_diar.py\u001b[0m in \u001b[0;36mcallback_sim\u001b[0;34m(self, sample_audio)\u001b[0m\n\u001b[1;32m   1903\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpunctuation_model_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_word_and_word_ts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1905\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fix_speaker_label_per_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_ts_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_diar_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1906\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_speaker_label_per_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_ts_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_diar_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1907\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/streaming_mulspk_asr/NeMo/examples/speaker_tasks/diarization/streaming_asr_and_diar.py\u001b[0m in \u001b[0;36m_fix_speaker_label_per_word\u001b[0;34m(self, words, word_ts_list, pred_diar_labels)\u001b[0m\n\u001b[1;32m   1528\u001b[0m                 \u001b[0mword_speaker_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspk_int\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1530\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_speaker_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1531\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealign_speaker_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_speaker_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if simulation:\n",
    "    samplerate, sdata = wavfile.read(diar.single_audio_file_path)\n",
    "    for index in range(int(np.floor(sdata.shape[0]/asr_diar.n_frame_len))):\n",
    "        asr_diar.buffer_counter = index\n",
    "        sample_audio = sdata[asr_diar.CHUNK_SIZE*(asr_diar.buffer_counter):asr_diar.CHUNK_SIZE*(asr_diar.buffer_counter+1)]\n",
    "        asr_diar.callback_sim(sample_audio)\n",
    "else:\n",
    "    isTorch = torch.cuda.is_available()\n",
    "    asr_diar.rttm_file_path = None\n",
    "    iface = gr.Interface(\n",
    "        fn=asr_diar.audio_queue_launcher,\n",
    "        inputs=[\n",
    "            gr.inputs.Audio(source=\"microphone\", type='filepath'), \n",
    "            \"state\",\n",
    "        ],\n",
    "        outputs=[\n",
    "            \"textbox\",\n",
    "            \"state\",\n",
    "        ],\n",
    "        layout=\"horizontal\",\n",
    "        theme=\"huggingface\",\n",
    "        title=f\"NeMo Streaming Conformer CTC Large - English, CUDA:{isTorch}\",\n",
    "        description=\"Demo for English speech recognition using Conformer Transducers\",\n",
    "        allow_flagging='never',\n",
    "        live=True,\n",
    "    )\n",
    "    iface.launch(share=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da436545",
   "metadata": {},
   "source": [
    "Now, go to streaming_diarization_viewer.ipynb and check the realtime output."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
