{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664cde63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# emotional tts quick c1 iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a92464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading the datasets\n",
    "\n",
    "# !(mkdir /DataEmotionalTTS && \\\n",
    "\n",
    "!(cd /DataEmotionalTTS && \\\n",
    "    wget https://www.openslr.org/resources/110/thorsten-emotional_v02.tgz && \\\n",
    "    tar -zxvf thorsten-emotional_v02.tgz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7daef6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo W 2022-07-18 17:58:34 nemo_logging:349] /opt/conda/lib/python3.8/site-packages/apex/pyprof/__init__.py:5: FutureWarning: pyprof will be removed by the end of June, 2022\n",
      "      warnings.warn(\"pyprof will be removed by the end of June, 2022\", FutureWarning)\n",
      "    \n",
      "[NeMo I 2022-07-18 17:58:35 tokenize_and_classify:81] Creating ClassifyFst grammars. This might take some time...\n",
      "Created ../DataEmotionalTTS/thorsten-emotional_v02/cache_dir/_cased_de_tn_True_deterministic.far\n",
      "[NeMo I 2022-07-18 17:58:50 tokenize_and_classify:144] ClassifyFst grammars are saved to ../DataEmotionalTTS/thorsten-emotional_v02/cache_dir/_cased_de_tn_True_deterministic.far.\n",
      "Created ../DataEmotionalTTS/thorsten-emotional_v02/cache_dir/de_tn_True_deterministic_verbalizer.far\n",
      "[NeMo I 2022-07-18 17:58:53 verbalize_final:71] VerbalizeFinalFst grammars are saved to ../DataEmotionalTTS/thorsten-emotional_v02/cache_dir/de_tn_True_deterministic_verbalizer.far.\n"
     ]
    }
   ],
   "source": [
    "# create manifests, normalization and phonemization\n",
    "\n",
    "# !(cd NeMoEmotionalTTS && \\\n",
    "#     python get_data.py \\\n",
    "\n",
    "!(python scripts/dataset_processing/tts/openslr_emotional/get_data.py \\\n",
    "        --data-root ../DataEmotionalTTS/ \\\n",
    "        --val-size 0.1 \\\n",
    "        --test-size 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4f6953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2cc2cc4a34b961ef1657cc82dbd18875 does not exist for whisper category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a04446ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O', 't', 'T', 'Ü', '?', '.', 'ö', 'V', 'n', 'w', 'B', 'Z', 'N', 'A', 'm', 'g', 'P', 'f', 'e', 'z', 'D', 'S', 'k', 'j', 'K', 'E', 'h', 'b', 'ü', '-', '!', 'C', 'I', 'W', 'F', 'ä', 'x', 'r', 'U', 'M', 'u', 's', 'G', 'd', 'o', 'c', 'l', 'a', 'i', ' ', ':', 'J', 'L', 'p', 'R', '\"', 'y', 'ß', \"'\", ',', 'v', 'H'}\n"
     ]
    }
   ],
   "source": [
    "# phonemization\n",
    "## inside the phonemizer container\n",
    "\n",
    "from phonemizer.backend import EspeakBackend\n",
    "import json\n",
    "\n",
    "backend = EspeakBackend('de')\n",
    "unique_symbols = set()\n",
    "input_manifest_filepaths = [\"/DataEmotionalTTS/thorsten-emotional_v02/train_manifest\", \\\n",
    "                            \"/DataEmotionalTTS/thorsten-emotional_v02/test_manifest\", \\\n",
    "                            \"/DataEmotionalTTS/thorsten-emotional_v02/val_manifest\"]\n",
    "\n",
    "for input_manifest_filepath in input_manifest_filepaths:\n",
    "    output_manifest_filepath = input_manifest_filepath+\"_phonemes\"\n",
    "    records = []\n",
    "    n_text = []\n",
    "    with open(input_manifest_filepath + \".json\", \"r\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            d = json.loads(line)\n",
    "            records.append(d)\n",
    "            n_text.append(d['normalized_text'])\n",
    "\n",
    "    phonemized = backend.phonemize(n_text)\n",
    "    for line in n_text:\n",
    "        for char in line:\n",
    "            unique_symbols.add(char)\n",
    "    new_records = []\n",
    "    for i in range(len(records)):\n",
    "        records[i][\"is_phoneme\"] = 0\n",
    "        new_records.append(records[i])\n",
    "        phoneme_record = records[i].copy()\n",
    "        phoneme_record[\"normalized_text\"] = phonemized[i]\n",
    "        phoneme_record[\"is_phoneme\"] = 1\n",
    "        new_records.append(phoneme_record)\n",
    "\n",
    "    with open(output_manifest_filepath + \".json\", \"w\") as f:\n",
    "        for r in new_records:\n",
    "            f.write(json.dumps(r) + '\\n')\n",
    "print(unique_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52d00e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ''.join(unique_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dacc620e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63571a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['?', '.', '-', '!', ' ', ':', '\"', \"'\", ',']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[char for char in a if char not in \"ʊʃŋɜːɛɾəɪçɔøɡœɑÜ„1Q̃ɒʒÄɹÖʌθàó̈ðéɐáabcdefghijklmnopqrstuvwxyzäöüß\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef3e29a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md  neutral\t\t\t    train_manifest.json\n",
      "amused\t   sleepy\t\t\t    train_manifest_phonemes.json\n",
      "angry\t   surprised\t\t\t    val_manifest.json\n",
      "cache_dir  test_manifest.json\t\t    val_manifest_phonemes.json\n",
      "disgusted  test_manifest_phonemes.json\t    whisper\n",
      "drunk\t   thorsten-emotional-metadata.csv\n"
     ]
    }
   ],
   "source": [
    "!ls /DataEmotionalTTS/thorsten-emotional_v02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bca3d20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"ds_for_fastpitch_align\"\n",
      "\n",
      "manifest_filepath: \"train_manifest.json\"\n",
      "sup_data_path: \"sup_data\"\n",
      "sup_data_types: [ \"align_prior_matrix\", \"pitch\" ]\n",
      "whitelist_path: \"nemo_text_processing/text_normalization/de/data/whitelist.tsv\"\n",
      "\n",
      "dataset:\n",
      "  _target_: nemo.collections.tts.torch.data.TTSDataset\n",
      "  manifest_filepath: ${manifest_filepath}\n",
      "  sample_rate: 22050\n",
      "  sup_data_path: ${sup_data_path}\n",
      "  sup_data_types: ${sup_data_types}\n",
      "  n_fft: 1024\n",
      "  win_length: 1024\n",
      "  hop_length: 256\n",
      "  window: \"hann\"\n",
      "  n_mels: 80\n",
      "  lowfreq: 0\n",
      "  highfreq: null\n",
      "  max_duration: null\n",
      "  min_duration: 0.1\n",
      "  ignore_file: null\n",
      "  trim: false\n",
      "  pitch_fmin: 65.40639132514966\n",
      "  pitch_fmax: 2093.004522404789\n",
      "\n",
      "  text_normalizer:\n",
      "    _target_: nemo_text_processing.text_normalization.normalize.Normalizer\n",
      "    lang: de\n",
      "    input_case: cased\n",
      "    whitelist: ${whitelist_path}\n",
      "\n",
      "  text_normalizer_call_kwargs:\n",
      "    verbose: false\n",
      "    punct_pre_process: true\n",
      "    punct_post_process: true\n",
      "\n",
      "  text_tokenizer:\n",
      "    _target_: nemo.collections.tts.torch.tts_tokenizers.GermanCharsTokenizer\n",
      "    punct: true\n",
      "    apostrophe: true\n",
      "    pad_with_space: true\n",
      "    phonemes: true"
     ]
    }
   ],
   "source": [
    "# dataset config\n",
    "!cat scripts/dataset_processing/tts/openslr_emotional/ds_conf/ds_for_fastpitch_align.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c260d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e712996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/apex/pyprof/__init__.py:5: FutureWarning: pyprof will be removed by the end of June, 2022\n",
      "  warnings.warn(\"pyprof will be removed by the end of June, 2022\", FutureWarning)\n",
      "[NeMo W 2022-07-27 01:56:39 experimental:27] Module <class 'nemo.collections.tts.torch.tts_tokenizers.IPATokenizer'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo I 2022-07-27 01:56:40 tokenize_and_classify:81] Creating ClassifyFst grammars. This might take some time...\n",
      "Error executing job with overrides: ['manifest_filepath=/DataEmotionalTTS/thorsten-emotional_v02/train_manifest_phonemes.json', 'sup_data_path=/DataEmotionalTTS/thorsten-emotional_v02/phonemes/']\n",
      "Error in call to target 'nemo.collections.tts.torch.data.TTSDataset':\n",
      "FileNotFoundError(2, 'No such file or directory')\n",
      "full_key: dataset\n",
      "\n",
      "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# supplementary data creation (optional)\n",
    "!(PYTHONPATH=. python scripts/dataset_processing/tts/extract_sup_data.py \\\n",
    "        --config-path /NeMoEmotionalTTS/scripts/dataset_processing/tts/openslr_emotional/ds_conf \\\n",
    "        --config-name ds_for_fastpitch_align.yaml \\\n",
    "        manifest_filepath=/DataEmotionalTTS/thorsten-emotional_v02/train_manifest_phonemes.json \\\n",
    "        sup_data_path=/DataEmotionalTTS/thorsten-emotional_v02/phonemes/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12e5cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the pretrained model, run on host\n",
    "# ngc registry model download-version \"nvstaging/nemo/tts_de_fastpitchhifigan:1.10.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3029349b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-train fastpitch (with speaker and emotional embedding) on German neutral tts\n",
    "!(CUDA_VISIBLE_DEVICES=0 python examples/tts/fastpitch.py --config-path conf/de --config-name fastpitch_align_22050 \\\n",
    "    name=\"c1e1-FastPitch-pretrain\" \\\n",
    "    model.train_ds.dataloader_params.batch_size=32 \\\n",
    "    model.validation_ds.dataloader_params.batch_size=32 \\\n",
    "    train_dataset=/DataEmotionalTTS/openslr-95-german-neutral-tts/thorsten-de/train_manifest_phonemes.json \\\n",
    "    validation_datasets=/DataEmotionalTTS/openslr-95-german-neutral-tts/thorsten-de/val_manifest_phonemes.json \\\n",
    "    sup_data_path=/DataEmotionalTTS/openslr-95-german-neutral-tts/thorsten-de/phonemes5/ \\\n",
    "    whitelist_path=nemo_text_processing/text_normalization/de/data/whitelist.tsv \\\n",
    "    exp_manager.exp_dir=/resultGermanTTS \\\n",
    "    trainer.max_epochs=100 \\\n",
    "    pitch_mean=132.524658203125 \\\n",
    "    pitch_std=pitch_std: 37.389366149902344 \\\n",
    "    +exp_manager.create_wandb_logger=true \\\n",
    "    +exp_manager.wandb_logger_kwargs.name=\"072620221311_c1e1-FastPitch-pretrain\" \\\n",
    "    +exp_manager.wandb_logger_kwargs.project=\"EmotionalTTS\" | tee -a 072620221311_c1e1-FastPitch-pretrain.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3385e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# monitor performance of pre-trained fastpitch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbca6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetune the model trained in the last cell\n",
    "!(CUDA_VISIBLE_DEVICES=0 python examples/tts/fastpitch_finetune.py --config-path conf/de --config-name fastpitch_align_v1.05.yaml \\\n",
    "    name=\"c1e1-FastPitch-finetune\" \\\n",
    "    model.train_ds.dataloader_params.batch_size=32 \\\n",
    "    model.validation_ds.dataloader_params.batch_size=32 \\\n",
    "    train_dataset=/DataEmotionalTTS/thorsten-emotional_v02/train_manifest_phonemes.json \\\n",
    "    validation_datasets=/DataEmotionalTTS/thorsten-emotional_v02/val_manifest_phonemes.json \\\n",
    "    sup_data_path=/DataEmotionalTTS/thorsten-emotional_v02/train_manifest_phonemes.json \\\n",
    "    whitelist_path=nemo_text_processing/text_normalization/de/data/whitelist.tsv \\\n",
    "    exp_manager.exp_dir=/resultEmotionalTTS \\\n",
    "    +init_from_nemo_model=/DataEmotionalTTS/tts_de_fastpitchhifigan_v1.10.0/tts_de_fastpitch_align.nemo \\\n",
    "    +trainer.max_steps=1000 ~trainer.max_epochs \\\n",
    "    trainer.check_val_every_n_epoch=25 \\\n",
    "    model.n_speakers=1 \\\n",
    "    model.n_emotions=8 \\\n",
    "    model.optim.lr=2e-4 \\\n",
    "    ~model.optim.sched model.optim.name=adamw trainer.devices=1 trainer.strategy=null \\\n",
    "    pitch_mean=169.59390258789062 \\\n",
    "    pitch_std=103.64842224121094 \\\n",
    "    +exp_manager.create_wandb_logger=true \\\n",
    "    +exp_manager.wandb_logger_kwargs.name=\"072620221311_c1e1-FastPitch-finetune\" \\\n",
    "    +exp_manager.wandb_logger_kwargs.project=\"EmotionalTTS\" | tee -a 072620221311_c1e1-FastPitch-pretrain.log)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
