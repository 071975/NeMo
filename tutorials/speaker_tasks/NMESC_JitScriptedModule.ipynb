{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b2503c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speaker Clustering: Torch Scripted Module Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a88f26",
   "metadata": {},
   "source": [
    "Provide the NeMo path to `NEMO_BRANCH_PATH`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "45d90716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check NeMo PATH: ['/home/taejinp/projects/diar_torch/NeMo/nemo']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# NEMO_BRANCH_PATH = '/your/path/to/diar_torch/NeMo/'\n",
    "NEMO_BRANCH_PATH = '/home/taejinp/projects/diar_torch/NeMo/'\n",
    "sys.path.insert(0, NEMO_BRANCH_PATH)\n",
    "import nemo\n",
    "print(\"Check NeMo PATH:\", nemo.__path__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "20b45939",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fc61cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemo.collections.asr.parts.utils.nmesc_clustering_export import SpeakerClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8f18d3",
   "metadata": {},
   "source": [
    "Download an example input dictionary file `uniq_scale_dict`:\n",
    "https://drive.google.com/file/d/1gQ7pqKnHk4v9zt52ECkJBeQL-aN38pEI/view?usp=sharing\n",
    "\n",
    "Please save it to your local path such as:   \n",
    "`example_file_path = \"/home/taejinp/Downloads/uniq_scale_dict.pt\"`\n",
    "\n",
    "This file has been created using scale lengths of :   \n",
    "`[1.5, 1.25, 1.0, 0.75, 0.5]`  \n",
    "and shift length of :  \n",
    "`[0.75, 0.75, 0.5, 0.375, 0.25]`  \n",
    "\n",
    "Scale indexes are:   \n",
    "`[0, 1, 2, 3, 4]`  \n",
    "\n",
    "Base scale is the finest (shortest) scale which is also the unit of decision.   \n",
    "In this example, base scale index is `4`.  \n",
    "In this example, base scale has length of 0.5 second and shift length (hop length) of 0.25 second.  \n",
    "\n",
    "Each of scale contains torch.tensors with different sizes. Check out the following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "481e1c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uniq_scale_dict keys:\n",
      " dict_keys([0, 1, 2, 3, 4])\n",
      "Base scale contents\n",
      " dict_keys(['embeddings', 'time_stamps'])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1577, 192])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([1577, 2])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([788, 192])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([788, 2])\n"
     ]
    }
   ],
   "source": [
    "example_file_path = \"/home/taejinp/Downloads/uniq_scale_dict.pt\"\n",
    "uniq_scale_dict = torch.load(example_file_path)\n",
    "\n",
    "\n",
    "# It contains integer scale indexes\n",
    "print(\"uniq_scale_dict keys:\\n\", uniq_scale_dict.keys())\n",
    "\n",
    "# Each scale key contains (1) embeddings (2) time_stamps\n",
    "print(\"Base scale contents\\n\", uniq_scale_dict[4].keys())\n",
    "\n",
    "# Dimension: (Number of index-4 (5th) scale segmensts) x (embedding dimension, 192 in this case)\n",
    "print(type(uniq_scale_dict[4]['embeddings']))\n",
    "print(uniq_scale_dict[4]['embeddings'].shape)\n",
    "\n",
    "# Dimension: (Number of index-4 (5th) scale segmensts) x 2 (start and end time stamps)\n",
    "print(type(uniq_scale_dict[4]['time_stamps']))\n",
    "print(uniq_scale_dict[4]['time_stamps'].shape)\n",
    "\n",
    "\n",
    "# Dimension: (Number of index-2 (3rd) scale segmensts) x (embedding dimension, 192 in this case)\n",
    "print(type(uniq_scale_dict[2]['embeddings']))\n",
    "print(uniq_scale_dict[2]['embeddings'].shape)\n",
    "\n",
    "# Dimension: (Number of index-2 (3rd) scale segmensts) x 2 (start and end time stamps)\n",
    "print(type(uniq_scale_dict[2]['time_stamps']))\n",
    "print(uniq_scale_dict[2]['time_stamps'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4771d970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup a multiscale weight vector. Equal weights\n",
    "multiscale_weights = torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0]).unsqueeze(0).to(device)\n",
    "multiscale_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2be65c9",
   "metadata": {},
   "source": [
    "Now, create a `SpeakerClustering` class instance and convert it to torch.jit.script module. This will create recursive script module since all the sub-fucntions used in this class is all torch.jit.script-decorated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b3a168e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "\n",
    "speaker_clustering = SpeakerClustering(\n",
    "            max_num_speaker=8,\n",
    "            max_rp_threshold=0.15,\n",
    "            sparse_search_volume=30,\n",
    "            multiscale_weights=multiscale_weights,\n",
    "            cuda=True)\n",
    "\n",
    "scripted_speaker_clustering = torch.jit.script(speaker_clustering)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc14451",
   "metadata": {},
   "source": [
    "Now, run the speaker clustering model with the following line. You can check the clustered labels and estimated number of speakers. The output is also torch.tensor format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fde3c07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster labels: tensor([0, 1, 1,  ..., 0, 0, 0], device='cuda:0')\n",
      "Set of speakers {0, 1}\n"
     ]
    }
   ],
   "source": [
    "cluster_labels = scripted_speaker_clustering.forward(\n",
    "    uniq_scale_dict,\n",
    "    oracle_num_speakers=-1,\n",
    "    )\n",
    "\n",
    "print(\"cluster labels:\", cluster_labels)\n",
    "print(\"Set of speakers\", set(cluster_labels.cpu().numpy().tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f3c045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
